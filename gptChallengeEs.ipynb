{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eca6be9-3ab2-4756-80a0-4880568d1cd7",
   "metadata": {},
   "source": [
    "# GPTChallenge: diagnóstico a partir de HCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de358c45-755b-4fad-9d68-72e591de8b4b",
   "metadata": {},
   "source": [
    "Vamos a trabajar con el corpus CodEsp (textos de historial clínico etiquetados con sus códigos CIE-10 Diagnóstico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d4da20-1cea-4309-941f-c2440b01801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, re, spacy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9e5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDoc(nlp, doc, nMinCharacters = 0):\n",
    "    \"\"\"\n",
    "    Normaliza un texto eliminando palabras por debajo del mínimo de caracteres, stop words y números.\n",
    "    Para ello, tokeniza empleando un modelo de Spacy.\n",
    "    \"\"\"\n",
    "    # Separar en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # Filtrar tokens\n",
    "    filtered_tokens = [t.lower_ for t in tokens if (len(t.text) >= nMinCharacters) and not t.is_punct and not re.match('[0-9]+', t.text)]\n",
    "    # Recombinamos los tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return doc\n",
    "\n",
    "def findMostSimilar(similarityDf: pd.DataFrame, data: pd.DataFrame, nMostSimilars: int = 1):\n",
    "    \"\"\"\n",
    "    Encuentra la etiqueta de los documentos más similares.\n",
    "    \"\"\"\n",
    "    # Crear df de resultados\n",
    "    results = pd.DataFrame(index = similarityDf.index, columns = ['archivoMostSimilar', 'similarity', 'codigosPred'])\n",
    "\n",
    "    for index, row in similarityDf.iterrows():\n",
    "        \n",
    "        # Buscar la máxima similitud\n",
    "        mostSimilar = row.nlargest(nMostSimilars)\n",
    "        \n",
    "        results.loc[index, 'archivoMostSimilar'] = mostSimilar.index.values\n",
    "        if nMostSimilars == 1:\n",
    "            results.loc[index, 'similarity'] = mostSimilar.values[0]\n",
    "        else:\n",
    "            results.loc[index, 'similarity'] = row[mostSimilar.index]\n",
    "\n",
    "    # Coger las etiquetas\n",
    "    if nMostSimilars == 1:\n",
    "        results['codigosPred'] = data.loc[np.squeeze(np.vstack(results['archivoMostSimilar'].values)), 'codigos'].values\n",
    "    else:\n",
    "        pass\n",
    "    return results\n",
    "\n",
    "def checkAccuracy(pred: pd.DataFrame, data: pd.DataFrame):\n",
    "    pred['codigos'] = data.loc[pred.index, 'codigos']\n",
    "\n",
    "    pred['guess'] = pred.apply(\n",
    "        lambda row: len(set(row['codigosPred']).intersection(row['codigos'])) / len(row['codigosPred']),\n",
    "        axis = 1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e8803",
   "metadata": {},
   "source": [
    "## Lectura y preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c8c08",
   "metadata": {},
   "source": [
    "### Conjunto de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566a8909-46d3-4ccd-8a67-96d819f60e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8316 entries, 0 to 8315\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   archivo  8316 non-null   object\n",
      " 1   codigo   8316 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 130.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#los códigos están en un TSV con un código por línea\n",
    "train_diag = pd.read_csv(\"data/train/train.tsv\", sep=\"\\t\", header=None, names=[\"archivo\", \"codigo\"])\n",
    "train_diag.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cbd33aa-1d54-419f-a1f1-728bb03b79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "r52    163\n",
      "r10    163\n",
      "r59    160\n",
      "r69    150\n",
      "r50    144\n",
      "      ... \n",
      "c31      1\n",
      "d62      1\n",
      "s53      1\n",
      "s34      1\n",
      "n81      1\n",
      "Name: count, Length: 918, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "918"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cogemos la categoría superior de cada código y las agrupamos\n",
    "train_diag['cat'] = train_diag['codigo'].str.extract(r'(\\w\\d\\d)')\n",
    "print(train_diag['cat'].value_counts())\n",
    "train_diag['cat'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eaf143a-b460-410e-8af2-a268181153d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r52', 'r10', 'r59', 'r69', 'r50', 'r60', 'i10', 'r11', 'n28', 'd49']\n"
     ]
    }
   ],
   "source": [
    "categories=train_diag['cat'].value_counts()[:10]\n",
    "top_categorias = categories.index.to_list()\n",
    "print(top_categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e458c1-01ec-4c48-8c3e-45f37e4553c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos sólo las etiquetas de este subconjunto\n",
    "train_diag = train_diag[np.isin(train_diag['cat'], top_categorias)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1befd52-7347-4e6d-8760-3a08b5fd8b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 562 entries, S0004-06142005000700014-1 to S2340-98942015000100005-1\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   texto    562 non-null    object\n",
      " 1   codigos  562 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#cargamos los dos conjuntos de train\n",
    "path = 'data/train/text_files/'\n",
    "\n",
    "corpus = []\n",
    "for f in [f for f in os.listdir(path) if f.endswith('.txt')]:\n",
    "    with open(os.path.join(path, f), encoding=\"utf8\") as text:\n",
    "        texto = text.read()\n",
    "    #buscamos códigos\n",
    "    file = f[:-4]\n",
    "    codigos = train_diag.query('archivo==@file')['cat'].to_list()\n",
    "    codigos = list(set(codigos))\n",
    "    if codigos:\n",
    "        corpus.append({\n",
    "            'archivo': file,\n",
    "            'texto': texto,\n",
    "            'codigos': codigos\n",
    "        })\n",
    "    \n",
    "df_train = pd.DataFrame(corpus).set_index('archivo')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf73334-972c-4746-829f-0891641a1b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>codigos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archivo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0211-69952013000500032-2</th>\n",
       "      <td>Mujer de 44 años, con antecedentes de exfumadora, HTA, DM tipo 2, obesidad mórbida (IMC 59,19 kg/m2), colecistectomía, apendicectomía, herniorrafia umbilical y cesárea. Se derivó a Cirugía General para realización de cirugía bariátrica mediante técnica de Larrad. Acudió a Urgencias a los dos meses de la intervención, refiriendo vómitos pospandriales de repetición desde el alta y episodio sincopal. En la exploración física destacó mal estado general, signos de depleción hidrosalina, PA 66/48 y PVC 4 cc H2O. Se realizó analítica: urea 284 mg/dl, Cr 6,98 mg/dl, Na 119 mmol/l, K 2,4 mmol/l, Cl 65 mmol/l, PCR 4,8 mg/dl, lactato 4,7 mmol/l, osmolaridad 333 mOsm/kg; hemograma: Hb 14,2 g/dl, VH 42%; leucocitos 19000/ul; plaquetas 251000/ul; gasometría venosa: pH 7,49, bicarbonato 25,9 mmol/l, pCO2 34 mmHg; función renal en orina: EF Na 0,11%, urea 276 mg/dl, Cr 274,8 mg/dl, Na 5 mmol/l, K 15,4 mmol/l. Se ingresó en Nefrología con el diagnóstico de IRA prerrenal secundaria a depleción de volumen, hiponatremia e hipopotasemia. Se inició reposición hidrosalina y corrección electrolítica progresiva con mejoría de la función renal, hasta su normalización. Durante su ingreso la paciente presentó insuficiencia respiratoria y shock séptico secundario a infección respiratoria. Se trasladó a la unidad de vigilancia intensiva, siendo exitus tras dos meses de ingreso.\\n\\n</td>\n",
       "      <td>[i10, r11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    texto  \\\n",
       "archivo                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "S0211-69952013000500032-2  Mujer de 44 años, con antecedentes de exfumadora, HTA, DM tipo 2, obesidad mórbida (IMC 59,19 kg/m2), colecistectomía, apendicectomía, herniorrafia umbilical y cesárea. Se derivó a Cirugía General para realización de cirugía bariátrica mediante técnica de Larrad. Acudió a Urgencias a los dos meses de la intervención, refiriendo vómitos pospandriales de repetición desde el alta y episodio sincopal. En la exploración física destacó mal estado general, signos de depleción hidrosalina, PA 66/48 y PVC 4 cc H2O. Se realizó analítica: urea 284 mg/dl, Cr 6,98 mg/dl, Na 119 mmol/l, K 2,4 mmol/l, Cl 65 mmol/l, PCR 4,8 mg/dl, lactato 4,7 mmol/l, osmolaridad 333 mOsm/kg; hemograma: Hb 14,2 g/dl, VH 42%; leucocitos 19000/ul; plaquetas 251000/ul; gasometría venosa: pH 7,49, bicarbonato 25,9 mmol/l, pCO2 34 mmHg; función renal en orina: EF Na 0,11%, urea 276 mg/dl, Cr 274,8 mg/dl, Na 5 mmol/l, K 15,4 mmol/l. Se ingresó en Nefrología con el diagnóstico de IRA prerrenal secundaria a depleción de volumen, hiponatremia e hipopotasemia. Se inició reposición hidrosalina y corrección electrolítica progresiva con mejoría de la función renal, hasta su normalización. Durante su ingreso la paciente presentó insuficiencia respiratoria y shock séptico secundario a infección respiratoria. Se trasladó a la unidad de vigilancia intensiva, siendo exitus tras dos meses de ingreso.\\n\\n   \n",
       "\n",
       "                              codigos  \n",
       "archivo                                \n",
       "S0211-69952013000500032-2  [i10, r11]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc77de8-8256-4653-9de0-690dacc58095",
   "metadata": {},
   "source": [
    "### Conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4d6ea92-47fd-462a-9067-33fdfdfd31a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192 entries, 0 to 191\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   archivo  192 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#los códigos están en un TSV con un código por línea\n",
    "test_diag = pd.read_csv(\"data/test/test.tsv\", sep = \"\\t\", header = None, names = [\"archivo\"])\n",
    "test_diag.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80ff5875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 192 entries, S2340-98942015000100005-1 to S2340-98942015000100005-1\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   texto   192 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "path = 'data/test/text_files/'\n",
    "\n",
    "corpus = []\n",
    "for f in [f for f in os.listdir(path) if f.endswith('.txt')]:\n",
    "    if os.path.splitext(f)[0] in test_diag['archivo'].values:\n",
    "        with open(os.path.join(path, f), encoding=\"utf8\") as text:\n",
    "            texto = text.read()\n",
    "            corpus.append({\n",
    "                'archivo': file,\n",
    "                'texto': texto\n",
    "            })\n",
    "    \n",
    "df_test = pd.DataFrame(corpus).set_index('archivo')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ae159e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archivo</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S2340-98942015000100005-1</th>\n",
       "      <td>Niño de ocho años con molestias abdominales intermitentes difusas en los últimos años, atribuidas a procesos banales agudos. Sin antecedentes personales ni familiares de interés. Sin infecciones de orina ni otra sintomatología urinaria.\\nCoincidiendo con un episodio de dolor abdominal en hemiabdomen derecho, se realizó una ecografía abdominal, en la que se objetivó una adenitis mesentérica y una dilatación de pelvis renal derecha leve, con sospecha de estenosis de la UPU. Sedimento de orina y urinocultivo normales.\\n\\nDesapareció la clínica de dolor abdominal espontáneamente, pero se remitió a Nefrología Pediátrica para control evolutivo.\\nEn la ecografía de control, estando asintomático, se seguía visualizando la dilatación de la vía urinaria con dilatación de pelvis renal derecha grado leve-moderada, por lo que se solicitó renograma isotópico (sospecha de estenosis de la unión pieloureteral). El renograma confirmó una ectasia obstructiva en riñón derecho. En el estudio de gammagrafía renal se objetivó aumento del tamaño renal derecho, con evidente hipocaptación en todo el borde medial, signos de dilatación de vía, con una función renal del 58,8% en riñón izquierdo y del 41,2% en riñón derecho.\\nAnte la dilatación del tracto urinario de causa obstructiva se remitió a Urología Infantil para intervención quirúrgica. Se colocó un catéter de nefrostomía durante unos meses para recuperar y evitar el deterioro de la función renal5,6. Tras la retirada del catéter de nefrostomía se siguieron realizando controles de imagen, clínicos y analíticos, normalizándose progresivamente.\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      texto\n",
       "archivo                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "S2340-98942015000100005-1  Niño de ocho años con molestias abdominales intermitentes difusas en los últimos años, atribuidas a procesos banales agudos. Sin antecedentes personales ni familiares de interés. Sin infecciones de orina ni otra sintomatología urinaria.\\nCoincidiendo con un episodio de dolor abdominal en hemiabdomen derecho, se realizó una ecografía abdominal, en la que se objetivó una adenitis mesentérica y una dilatación de pelvis renal derecha leve, con sospecha de estenosis de la UPU. Sedimento de orina y urinocultivo normales.\\n\\nDesapareció la clínica de dolor abdominal espontáneamente, pero se remitió a Nefrología Pediátrica para control evolutivo.\\nEn la ecografía de control, estando asintomático, se seguía visualizando la dilatación de la vía urinaria con dilatación de pelvis renal derecha grado leve-moderada, por lo que se solicitó renograma isotópico (sospecha de estenosis de la unión pieloureteral). El renograma confirmó una ectasia obstructiva en riñón derecho. En el estudio de gammagrafía renal se objetivó aumento del tamaño renal derecho, con evidente hipocaptación en todo el borde medial, signos de dilatación de vía, con una función renal del 58,8% en riñón izquierdo y del 41,2% en riñón derecho.\\nAnte la dilatación del tracto urinario de causa obstructiva se remitió a Urología Infantil para intervención quirúrgica. Se colocó un catéter de nefrostomía durante unos meses para recuperar y evitar el deterioro de la función renal5,6. Tras la retirada del catéter de nefrostomía se siguieron realizando controles de imagen, clínicos y analíticos, normalizándose progresivamente.\\n\\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b472f280-db6a-438d-8340-f7b19758399b",
   "metadata": {},
   "source": [
    "### Binarizar las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae41be51-448e-433b-b10f-b4236afbaa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# para entrenar un clasificador multi-etiqueta generamos una matriz binaria de las etiquetas\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(df_train['codigos'])\n",
    "\n",
    "#Guardamos las clases utilizadas en el conjunto de train\n",
    "clases = mlb.classes_\n",
    "num_classes = clases.shape\n",
    "print(num_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f59c35",
   "metadata": {},
   "source": [
    "## Procesamiento del lenguaje natural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cdde5f",
   "metadata": {},
   "source": [
    "### BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02e63e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download es_core_news_lg\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeb61cb",
   "metadata": {},
   "source": [
    "Obtenemos resultados ligeramente mejores sin realizar un preprocesamiento con la función `normalizeDoc()` previamente a la aplicación del *Bag of Words*. La adición de *n-grams* empeora los resultados de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb424683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_trainText = [normalizeDoc(nlp, doc) for doc in df_train['texto'].values]\n",
    "x_trainText = df_train['texto'].values\n",
    "x_testText = df_test['texto'].values\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x_trainArray = vectorizer.fit_transform(x_trainText)\n",
    "x_testArray = vectorizer.transform(x_testText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b0d0d",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9f9be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train_train, y_train_test = train_test_split(x_trainArray, y_train, test_size = 0.1, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d49be3",
   "metadata": {},
   "source": [
    "### Nuestro mejor modelo: MultiOutput con GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f35a7005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.62      0.73        13\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      0.75      0.86         8\n",
      "           3       0.80      0.57      0.67        14\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      0.93      0.97        15\n",
      "           6       1.00      0.31      0.47        13\n",
      "           7       1.00      0.92      0.96        12\n",
      "           8       0.88      0.88      0.88         8\n",
      "           9       1.00      1.00      1.00        17\n",
      "\n",
      "   micro avg       0.96      0.80      0.87       124\n",
      "   macro avg       0.96      0.80      0.85       124\n",
      "weighted avg       0.96      0.80      0.85       124\n",
      " samples avg       0.92      0.82      0.85       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = GradientBoostingClassifier(loss = 'exponential', n_estimators = 50, max_depth = 5, min_samples_split = 5, random_state = 3)\n",
    "model = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "model.fit(x_train, y_train_train)\n",
    "y_pred = model.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11916ec",
   "metadata": {},
   "source": [
    "### Coseno similitud (*manual*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8476ec88-d3f6-477f-8cc9-d298ce8077b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTag = df_train.index.values\n",
    "\n",
    "x_trainT, x_testT, xTag_train, xTag_test = train_test_split(x_train, xTag, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0689372a-2ed7-45d5-895c-92b4f773c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "x_trainVec = vectorizer.fit_transform(x_trainT)\n",
    "x_trainVecDf = pd.DataFrame(x_trainVec.toarray(), columns = vectorizer.get_feature_names_out(), index = xTag_train)\n",
    "\n",
    "x_testVec = vectorizer.transform(x_testT)\n",
    "x_testVecDf = pd.DataFrame(x_testVec.toarray(), columns = vectorizer.get_feature_names_out(), index = xTag_test)\n",
    "\n",
    "similarity = cosine_similarity(x_testVecDf, x_trainVecDf)\n",
    "similarityDf = pd.DataFrame(similarity, index = x_testVecDf.index, columns = x_trainVecDf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8e24959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>archivoMostSimilar</th>\n",
       "      <th>similarity</th>\n",
       "      <th>codigosPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0210-48062010000100019-4</th>\n",
       "      <td>S0210-48062005000600013-1</td>\n",
       "      <td>0.339525</td>\n",
       "      <td>[n28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1134-80462015000200005-1</th>\n",
       "      <td>S0212-16112010000600024-1</td>\n",
       "      <td>0.269564</td>\n",
       "      <td>[r10, r69, r11, r60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1139-76322009000400007-1</th>\n",
       "      <td>S1137-66272013000300020-1</td>\n",
       "      <td>0.352673</td>\n",
       "      <td>[r10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0376-78922014000100013-1</th>\n",
       "      <td>S0376-78922016000200012-1</td>\n",
       "      <td>0.40826</td>\n",
       "      <td>[r69, d49, i10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1130-01082007001100012-1</th>\n",
       "      <td>S0212-16112010000100017-1</td>\n",
       "      <td>0.221398</td>\n",
       "      <td>[r60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  archivoMostSimilar similarity  \\\n",
       "S0210-48062010000100019-4  S0210-48062005000600013-1   0.339525   \n",
       "S1134-80462015000200005-1  S0212-16112010000600024-1   0.269564   \n",
       "S1139-76322009000400007-1  S1137-66272013000300020-1   0.352673   \n",
       "S0376-78922014000100013-1  S0376-78922016000200012-1    0.40826   \n",
       "S1130-01082007001100012-1  S0212-16112010000100017-1   0.221398   \n",
       "\n",
       "                                    codigosPred  \n",
       "S0210-48062010000100019-4                 [n28]  \n",
       "S1134-80462015000200005-1  [r10, r69, r11, r60]  \n",
       "S1139-76322009000400007-1                 [r10]  \n",
       "S0376-78922014000100013-1       [r69, d49, i10]  \n",
       "S1130-01082007001100012-1                 [r60]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilarDf = findMostSimilar(similarityDf, df_train)\n",
    "\n",
    "mostSimilarDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1d8d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al menos 1 coincidencia: 0.624113475177305\n",
      "Accuracy media: 0.4052178318135765\n"
     ]
    }
   ],
   "source": [
    "mostSimilarDf = checkAccuracy(mostSimilarDf, df_train)\n",
    "print(f\"Al menos 1 coincidencia: {(mostSimilarDf['guess'] != 0).sum() / mostSimilarDf.shape[0]}\")\n",
    "print(f\"Accuracy media: {mostSimilarDf['guess'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651e603",
   "metadata": {},
   "source": [
    "### Otros modelos de clasificación multietiqueta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef20299",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a176f20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       1.00      0.25      0.40        16\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       1.00      0.07      0.13        14\n",
      "           4       1.00      0.25      0.40         8\n",
      "           5       0.75      0.20      0.32        15\n",
      "           6       0.33      0.08      0.12        13\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "   micro avg       0.79      0.09      0.16       124\n",
      "   macro avg       0.41      0.08      0.14       124\n",
      "weighted avg       0.43      0.09      0.14       124\n",
      " samples avg       0.17      0.08      0.11       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_target_classifier = RandomForestClassifier(n_estimators = 10, criterion = 'gini', n_jobs = 4, random_state = 3)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380064f",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "723f59cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.14        13\n",
      "           1       0.80      0.25      0.38        16\n",
      "           2       0.83      0.62      0.71         8\n",
      "           3       1.00      0.29      0.44        14\n",
      "           4       0.20      0.12      0.15         8\n",
      "           5       0.75      0.40      0.52        15\n",
      "           6       0.50      0.23      0.32        13\n",
      "           7       0.83      0.42      0.56        12\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.80      0.24      0.36        17\n",
      "\n",
      "   micro avg       0.70      0.27      0.39       124\n",
      "   macro avg       0.67      0.26      0.36       124\n",
      "weighted avg       0.72      0.27      0.37       124\n",
      " samples avg       0.38      0.25      0.29       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_target_classifier = MLPClassifier(activation = 'logistic', solver = 'adam', max_iter = 1000, random_state = 3)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b54f8",
   "metadata": {},
   "source": [
    "#### K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa4991c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.08      0.13        26\n",
      "           1       0.25      0.06      0.09        35\n",
      "           2       0.33      0.23      0.27        13\n",
      "           3       0.43      0.10      0.17        29\n",
      "           4       0.50      0.04      0.08        23\n",
      "           5       0.40      0.06      0.10        36\n",
      "           6       0.39      0.23      0.29        31\n",
      "           7       0.24      0.20      0.22        25\n",
      "           8       0.67      0.08      0.14        25\n",
      "           9       0.31      0.23      0.26        35\n",
      "\n",
      "   micro avg       0.34      0.13      0.18       278\n",
      "   macro avg       0.40      0.13      0.18       278\n",
      "weighted avg       0.40      0.13      0.17       278\n",
      " samples avg       0.19      0.11      0.13       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_target_classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd551adb",
   "metadata": {},
   "source": [
    "#### MultiOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628531d0",
   "metadata": {},
   "source": [
    "##### Regression Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "091125fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.42        26\n",
      "           1       0.88      0.43      0.58        35\n",
      "           2       0.56      0.69      0.62        13\n",
      "           3       0.87      0.45      0.59        29\n",
      "           4       0.78      0.30      0.44        23\n",
      "           5       0.83      0.42      0.56        36\n",
      "           6       0.53      0.26      0.35        31\n",
      "           7       0.77      0.40      0.53        25\n",
      "           8       0.86      0.24      0.38        25\n",
      "           9       0.88      0.40      0.55        35\n",
      "\n",
      "   micro avg       0.78      0.37      0.51       278\n",
      "   macro avg       0.80      0.39      0.50       278\n",
      "weighted avg       0.81      0.37      0.50       278\n",
      " samples avg       0.50      0.35      0.40       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = LogisticRegression(penalty = 'l2', solver = 'newton-cg', max_iter = 1000, multi_class = 'multinomial')\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "417a9432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.27      0.39        26\n",
      "           1       0.79      0.54      0.64        35\n",
      "           2       0.56      0.69      0.62        13\n",
      "           3       0.78      0.48      0.60        29\n",
      "           4       0.64      0.39      0.49        23\n",
      "           5       0.83      0.53      0.64        36\n",
      "           6       0.53      0.26      0.35        31\n",
      "           7       0.79      0.44      0.56        25\n",
      "           8       0.88      0.28      0.42        25\n",
      "           9       0.89      0.49      0.63        35\n",
      "\n",
      "   micro avg       0.75      0.43      0.55       278\n",
      "   macro avg       0.74      0.44      0.53       278\n",
      "weighted avg       0.75      0.43      0.54       278\n",
      " samples avg       0.55      0.44      0.46       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = PassiveAggressiveClassifier(random_state = 3)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "102daac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.27      0.35        26\n",
      "           1       0.78      0.51      0.62        35\n",
      "           2       0.69      0.69      0.69        13\n",
      "           3       0.88      0.48      0.62        29\n",
      "           4       0.58      0.48      0.52        23\n",
      "           5       0.86      0.50      0.63        36\n",
      "           6       0.41      0.29      0.34        31\n",
      "           7       0.71      0.68      0.69        25\n",
      "           8       0.58      0.28      0.38        25\n",
      "           9       0.76      0.37      0.50        35\n",
      "\n",
      "   micro avg       0.68      0.44      0.54       278\n",
      "   macro avg       0.68      0.46      0.54       278\n",
      "weighted avg       0.69      0.44      0.53       278\n",
      " samples avg       0.53      0.45      0.46       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = SGDClassifier(loss = 'squared_hinge', penalty = 'elasticnet', random_state = 3)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b696cc",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9781407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       1.00      0.31      0.48        16\n",
      "           2       1.00      0.25      0.40         8\n",
      "           3       1.00      0.14      0.25        14\n",
      "           4       0.50      0.12      0.20         8\n",
      "           5       1.00      0.33      0.50        15\n",
      "           6       0.00      0.00      0.00        13\n",
      "           7       0.67      0.17      0.27        12\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.80      0.24      0.36        17\n",
      "\n",
      "   micro avg       0.88      0.17      0.28       124\n",
      "   macro avg       0.60      0.16      0.25       124\n",
      "weighted avg       0.63      0.17      0.26       124\n",
      " samples avg       0.27      0.15      0.18       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = RandomForestClassifier(n_estimators = 10)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5c074",
   "metadata": {},
   "source": [
    "##### Gradient Boosting: Grid Search (mejor modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59e6add7-769c-40b6-931b-1fca0721a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters: {'estimator__max_depth': 5, 'estimator__min_samples_split': 5, 'estimator__n_estimators': 50}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.38      0.49        26\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       0.69      0.69      0.69        13\n",
      "           3       0.87      0.69      0.77        29\n",
      "           4       1.00      0.87      0.93        23\n",
      "           5       1.00      0.94      0.97        36\n",
      "           6       0.82      0.45      0.58        31\n",
      "           7       1.00      0.92      0.96        25\n",
      "           8       0.96      0.92      0.94        25\n",
      "           9       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       0.93      0.80      0.86       278\n",
      "   macro avg       0.90      0.79      0.83       278\n",
      "weighted avg       0.92      0.80      0.85       278\n",
      " samples avg       0.88      0.80      0.82       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = GradientBoostingClassifier(loss = 'exponential', random_state = 3)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [40, 50, 60],\n",
    "    'estimator__max_depth': [3, 5, 7],\n",
    "    'estimator__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
    "\n",
    "grid_search = GridSearchCV(multi_target_classifier, param_grid, cv = 5, scoring = f1_scorer, n_jobs = 4, verbose = 1)\n",
    "grid_search.fit(x_train, y_train_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_estimator = grid_search.best_estimator_\n",
    "best_estimator.fit(x_train, y_train_train)\n",
    "\n",
    "y_pred = best_estimator.predict(x_test)\n",
    "\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9846b1",
   "metadata": {},
   "source": [
    "Intentamos mejorar el modelo añadiendo un `AdaBoostClassifier` para mejorar el *fitting* del estimador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a4bdeabe-13e4-48f6-bc3c-0538b3394303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.46      0.57        26\n",
      "           1       1.00      0.83      0.91        35\n",
      "           2       0.56      0.69      0.62        13\n",
      "           3       0.86      0.66      0.75        29\n",
      "           4       1.00      0.87      0.93        23\n",
      "           5       1.00      0.94      0.97        36\n",
      "           6       0.88      0.45      0.60        31\n",
      "           7       1.00      0.92      0.96        25\n",
      "           8       0.96      0.92      0.94        25\n",
      "           9       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       0.93      0.78      0.85       278\n",
      "   macro avg       0.90      0.77      0.82       278\n",
      "weighted avg       0.92      0.78      0.84       278\n",
      " samples avg       0.84      0.78      0.79       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator = GradientBoostingClassifier(loss = 'exponential', criterion = 'friedman_mse', n_estimators = 50, max_depth = 5, min_samples_split = 5, random_state = 3)\n",
    "base_classifier = AdaBoostClassifier(estimator = estimator, n_estimators = 100, random_state = 3)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838794ad",
   "metadata": {},
   "source": [
    "##### Light Gradient-Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e693b9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.54      0.60        26\n",
      "           1       1.00      0.74      0.85        35\n",
      "           2       0.77      0.77      0.77        13\n",
      "           3       0.81      0.76      0.79        29\n",
      "           4       1.00      0.87      0.93        23\n",
      "           5       1.00      0.89      0.94        36\n",
      "           6       0.56      0.48      0.52        31\n",
      "           7       1.00      0.84      0.91        25\n",
      "           8       0.96      0.92      0.94        25\n",
      "           9       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       0.89      0.78      0.83       278\n",
      "   macro avg       0.88      0.78      0.82       278\n",
      "weighted avg       0.89      0.78      0.83       278\n",
      " samples avg       0.82      0.77      0.77       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = lgb.LGBMClassifier(boosting_type = 'dart', n_estimators = 50, objective = 'binary', random_state = 3)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train.astype(np.float32), y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test.astype(np.float32))\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c7119e-b68d-447f-ae89-ef18c223ebf8",
   "metadata": {},
   "source": [
    "## Guardar predicciones de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6167ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_testArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a58efb1",
   "metadata": {},
   "source": [
    "En caso de que algún texto se haya quedado sin etiquetar, asignamos etiquetas de manera aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "53288e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-labeled texts: [ 84  85  91  92 108 138 139 140 155 168 169 176 189]\n"
     ]
    }
   ],
   "source": [
    "zeroIdx = np.where(np.sum(y_test_pred, axis = 1) == 0)[0]\n",
    "if zeroIdx.size > 0:\n",
    "    print('Non-labeled texts:', zeroIdx)\n",
    "    probs = model.predict_proba(x_testArray)\n",
    "    for idx in zeroIdx:\n",
    "        oneProb = []\n",
    "        for probArray, classes in zip(probs, model.classes_):\n",
    "            p = probArray[idx][classes == 1][0]\n",
    "            oneProb.append(p)\n",
    "        y_test_pred[idx, np.argmax(oneProb)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ff863c1c-9821-4ad4-a912-1abe400f5c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192 entries, 0 to 191\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   archivo  192 non-null    object\n",
      " 1   d49      192 non-null    int32 \n",
      " 2   i10      192 non-null    int32 \n",
      " 3   n28      192 non-null    int32 \n",
      " 4   r10      192 non-null    int32 \n",
      " 5   r11      192 non-null    int32 \n",
      " 6   r50      192 non-null    int32 \n",
      " 7   r52      192 non-null    int32 \n",
      " 8   r59      192 non-null    int32 \n",
      " 9   r60      192 non-null    int32 \n",
      " 10  r69      192 non-null    int32 \n",
      "dtypes: int32(10), object(1)\n",
      "memory usage: 9.1+ KB\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(y_test_pred, index = df_test.index, columns = clases)\n",
    "results.reset_index(inplace = True)\n",
    "\n",
    "results.to_csv('results/bow-multioutput-gradientboosting.csv', index = False)\n",
    "results.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

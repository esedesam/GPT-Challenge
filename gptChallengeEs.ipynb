{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eca6be9-3ab2-4756-80a0-4880568d1cd7",
   "metadata": {},
   "source": [
    "# GPTChallenge: diagn贸stico a partir de HCE\n",
    "\n",
    "**Grupo 2: GPTSovereigns** ㄢ\n",
    "\n",
    "Integrantes: \n",
    "- Mart铆nez Leal, Jes煤s\n",
    "- Ortega Mediavilla, Samuel\n",
    "- Vicente Mart铆nez, Pablo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff556ab",
   "metadata": {},
   "source": [
    "**OBJETIVO**. Clasificar texto procedente de historias cl铆nicas electr贸nicas en c贸digo CIE-10 usando ChatGPT.\n",
    "\n",
    "El CIE-10 (Clasificaci贸n Internacional de Enfermedades, d茅cima edici贸n) es un sistema de clasificaci贸n m茅dica utilizado para codificar y clasificar enfermedades y otros problemas de salud. ASigna c贸digos alfanum茅ricos a una amplia variedad de enfermedades, trastornos, lesiones, causas externas de morbilidad y otros problemas de salud. Cada c贸digo est谩 compuesto por entre 3 y 7 caracteres, que proporcionan informaci贸n detallada sobre la condici贸n m茅dica o el evento en cuesti贸n.\n",
    "\n",
    "Tendremos un **conjunto de train** con historias cl铆nicas electr贸nicas y varias etiquetas CIE-10 asociadas, as铆 como un **conjunto de test** *no etiquetado*. El resultado de la predicci贸n solo podr谩 ser visto al subirlo a una p谩gina web que nos brindaron los profesores, disponiendo de un m谩ximo de **3 intentos**. Para ello, previamente deberemos guardar las predicciones sobre este conjunto en un **dataframe** que exportaremos a formato `.csv`.\n",
    "\n",
    "Ser谩 necesario que demos tambi茅n nuestro historial de chat en ChatGPT (uno por integrante) en lo relacionado con el proyecto, por lo que ser谩 necesario dar el enlace directo de este (al final del notebook est谩).\n",
    "\n",
    "Por 煤ltimo, se deber谩 escribir un art铆culo cient铆fico con las secciones siguientes: 1. Introducci贸n, 2. Materiales y m茅todos, 3. Resultados, 4. Discusi贸n y 5. Conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5ba28",
   "metadata": {},
   "source": [
    "Aunque el dataset de **train** tiene casi 1000 c贸digos, tomaremos solo las historias cl铆nicas con los **10 c贸digos m谩s frecuentes**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49d9698",
   "metadata": {},
   "source": [
    "=============================================================================================================================================================================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de358c45-755b-4fad-9d68-72e591de8b4b",
   "metadata": {},
   "source": [
    "Vamos a trabajar con el corpus **CodEsp** (textos de historial cl铆nico etiquetados con sus c贸digos CIE-10 Diagn贸stico). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdaf085",
   "metadata": {},
   "source": [
    "## Carga de librer铆as y definici贸n de funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d4da20-1cea-4309-941f-c2440b01801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # used for data manipulation\n",
    "import os, re, spacy # used for text processing, regular expressions, and nlp purposes\n",
    "import numpy as np # used for numerical operations\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer # used for encoding labels\n",
    "from sklearn.feature_extraction.text import CountVectorizer # used for text vectorization\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier # used for classification\n",
    "from sklearn.neighbors import KNeighborsClassifier # used for classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier # used for classification, ensemble methods\n",
    "from sklearn.multioutput import MultiOutputClassifier # used for multi-label classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # used for splitting data, hyperparameter tuning\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score # used for evaluation\n",
    "from sklearn.metrics.pairwise import cosine_similarity # used for similarity calculation\n",
    "\n",
    "import lightgbm as lgb # used for classification\n",
    "from scipy.sparse import vstack # used for stacking sparse matrices\n",
    "\n",
    "pd.options.display.max_colwidth = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d476c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3 # semilla uwu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9e5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDoc(nlp, doc, nMinCharacters = 0):\n",
    "    \"\"\"\n",
    "    Normaliza un texto eliminando palabras por debajo del m铆nimo de caracteres, stop words y n煤meros.\n",
    "    Para ello, tokeniza empleando un modelo de Spacy.\n",
    "    \"\"\"\n",
    "    # Separar en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # Filtrar tokens\n",
    "    filtered_tokens = [t.lower_ for t in tokens if (len(t.text) >= nMinCharacters) and not t.is_punct and not re.match('[0-9]+', t.text)] # Filtrar palabras por longitud y quitar n煤meros y signos de puntuaci贸n\n",
    "    # Recombinamos los tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return doc\n",
    "\n",
    "def findMostSimilar(similarityDf: pd.DataFrame, data: pd.DataFrame, nMostSimilars: int = 1):\n",
    "    \"\"\"\n",
    "    Encuentra la etiqueta de los documentos m谩s similares.\n",
    "    \"\"\"\n",
    "    # Crear df de resultados\n",
    "    results = pd.DataFrame(index = similarityDf.index, columns = ['archivoMostSimilar', 'similarity', 'codigosPred'])\n",
    "\n",
    "    for index, row in similarityDf.iterrows():\n",
    "        \n",
    "        # Buscar la m谩xima similitud\n",
    "        mostSimilar = row.nlargest(nMostSimilars)\n",
    "        \n",
    "        results.loc[index, 'archivoMostSimilar'] = mostSimilar.index.values\n",
    "        if nMostSimilars == 1:\n",
    "            results.loc[index, 'similarity'] = mostSimilar.values[0]\n",
    "        else:\n",
    "            results.loc[index, 'similarity'] = row[mostSimilar.index]\n",
    "\n",
    "    # Coger las etiquetas\n",
    "    if nMostSimilars == 1:\n",
    "        results['codigosPred'] = data.loc[np.squeeze(np.vstack(results['archivoMostSimilar'].values)), 'codigos'].values\n",
    "    else:\n",
    "        pass\n",
    "    return results\n",
    "\n",
    "def checkAccuracy(pred: pd.DataFrame, data: pd.DataFrame):\n",
    "    pred['codigos'] = data.loc[pred.index, 'codigos']\n",
    "\n",
    "    pred['guess'] = pred.apply(\n",
    "        lambda row: len(set(row['codigosPred']).intersection(row['codigos'])) / len(row['codigosPred']),\n",
    "        axis = 1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e8803",
   "metadata": {},
   "source": [
    "## Lectura y preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c8c08",
   "metadata": {},
   "source": [
    "### Conjunto de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566a8909-46d3-4ccd-8a67-96d819f60e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8316 entries, 0 to 8315\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   archivo  8316 non-null   object\n",
      " 1   codigo   8316 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 130.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#los c贸digos est谩n en un TSV con un c贸digo por l铆nea\n",
    "train_diag = pd.read_csv(\"data/train/train.tsv\", sep=\"\\t\", header=None, names=[\"archivo\", \"codigo\"])\n",
    "train_diag.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cbd33aa-1d54-419f-a1f1-728bb03b79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "r52    163\n",
      "r10    163\n",
      "r59    160\n",
      "r69    150\n",
      "r50    144\n",
      "      ... \n",
      "c31      1\n",
      "d62      1\n",
      "s53      1\n",
      "s34      1\n",
      "n81      1\n",
      "Name: count, Length: 918, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "918"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cogemos la categor铆a superior de cada c贸digo y las agrupamos\n",
    "train_diag['cat'] = train_diag['codigo'].str.extract(r'(\\w\\d\\d)')\n",
    "print(train_diag['cat'].value_counts())\n",
    "train_diag['cat'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eaf143a-b460-410e-8af2-a268181153d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r52', 'r10', 'r59', 'r69', 'r50', 'r60', 'i10', 'r11', 'n28', 'd49']\n"
     ]
    }
   ],
   "source": [
    "categories=train_diag['cat'].value_counts()[:10] # cogemos las 10 categor铆as m谩s comunes\n",
    "top_categorias = categories.index.to_list()\n",
    "print(top_categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e458c1-01ec-4c48-8c3e-45f37e4553c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos s贸lo las etiquetas de este subconjunto\n",
    "train_diag = train_diag[np.isin(train_diag['cat'], top_categorias)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1befd52-7347-4e6d-8760-3a08b5fd8b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 562 entries, S0004-06142005000700014-1 to S2340-98942015000100005-1\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   texto    562 non-null    object\n",
      " 1   codigos  562 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#cargamos los dos conjuntos de train\n",
    "path = 'data/train/text_files/'\n",
    "\n",
    "corpus = []\n",
    "for f in [f for f in os.listdir(path) if f.endswith('.txt')]:\n",
    "    with open(os.path.join(path, f), encoding=\"utf8\") as text:\n",
    "        texto = text.read()\n",
    "    #buscamos c贸digos\n",
    "    file = f[:-4]\n",
    "    codigos = train_diag.query('archivo==@file')['cat'].to_list()\n",
    "    codigos = list(set(codigos))\n",
    "    if codigos:\n",
    "        corpus.append({\n",
    "            'archivo': file,\n",
    "            'texto': texto,\n",
    "            'codigos': codigos\n",
    "        })\n",
    "    \n",
    "df_train = pd.DataFrame(corpus).set_index('archivo')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf73334-972c-4746-829f-0891641a1b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>codigos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archivo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1130-01082008001000010-1</th>\n",
       "      <td>Var贸n de 43 a帽os originario de Marruecos, que ingres贸 en nuestro servicio por cuadro de 4 d铆as de evoluci贸n de ictericia mucocut谩nea indolora, coluria y prurito generalizado. Como 煤nicos antecedentes de inter茅s destacaban una tuberculosis tratada, hipercolesterolemia en tratamiento diet茅tico y tabaquismo leve. La anal铆tica mostr贸 los siguientes datos: bilirrubina 19,44 mg/dl, GOT 110 UI/ml, GPT 371 UI/ml, GGT 632 UI/ml, FA 787 UI/ml, LDH 394 UI/ml. Amilasa y lipasa fueron normales en todo momento. Destacaba tambi茅n una hipergammaglobulinemia (gammaglobulina 1,56%), con IgG 1840 UI/ml (751-1.560 UI/ml). El marcador CA 19-9 era de 82 UI/ml. Los autoanticuerpos (ANA, AMA, AMA-2, ANCA, LKM1, SMA, SLA y F-actina) y serolog铆as para virus y bacterias (VHA, VHB, VHC, HIV, CMV, VEB, VVZ, VHS, virus de la parotidis, parvovirus B19, Brucella, Borrelia, Coxiella, Leishmania, Rickettsias y Toxoplasma) fueron negativos. La ecograf铆a abdominal mostr贸 dilataci贸n de la v铆a biliar intra- y extrahep谩tica y la ecoendoscopia (USE) un p谩ncreas aumentado de tama帽o con una lesi贸n focal de 3 cm a nivel de cabeza y leve dilataci贸n posterior del conducto pancre谩tico. La TAC toracoabdominal objetiv贸 adem谩s un p谩ncreas aumentado globalmente de tama帽o, hipodenso, con un halo peripancre谩tico hipodenso, con borde liso, sin afectaci贸n de la grasa peripancre谩tica, y, a nivel retroperitoneal, en localizaci贸n peria贸rtica con extensi贸n a territorio iliaco bilateral, un tejido denso rodeando dichas estructuras vasculares como un estuche, siendo todo ello compatible con pancreatitis autoinmune con fibrosis retroperitoneal. Ante la persistencia de prurito y la colestasis manifiesta se realiz贸 un drenaje biliar percut谩neo mostrando la colangiograf铆a una lesi贸n estenosante en col茅doco distal sugerente de neoplasia pancre谩tica. Ante dicha posibilidad como primer diagn贸stico diferencial, se realiz贸 una punci贸n-aspiraci贸n con aguja fina guiada por USE con citolog铆a negativa para c茅lulas malignas y tinci贸n Zielh negativa. Dada la ausencia de confirmaci贸n de neoplasia, y con la sospecha de pancreatitis autoinmune, se realiz贸 una colangiopancreatograf铆a retr贸grada endosc贸pica (CPRE) observando dilataci贸n de la v铆a biliar principal con una estenosis regular en su porci贸n distal, de unos 3-4 cm, de aspecto benigno, sobre la que se coloc贸 una endopr贸tesis pl谩stica. Se inici贸 tratamiento con corticoides (metilprednisolona a dosis de 32 mg/d铆a) y se retir贸 el drenaje percut谩neo. Con el diagn贸stico de probable PAI el paciente fue dado de alta y seguido de forma ambulatoria comprobando normalizaci贸n de todos los par谩metros anal铆ticos y la resoluci贸n en la TAC abdominal de control, al mes y a los 4 meses, de las lesiones descritas inicialmente, con normalizaci贸n del tama帽o y aspecto pancre谩tico y desaparici贸n de la fibrosis retroperitoneal. La dosis de corticoides fue disminuy茅ndose progresivamente hasta su retirada completa al 4潞 mes, retir谩ndose tambi茅n la endopr贸tesis biliar. Hasta la fecha actual, tras 24 meses de seguimiento, el paciente ha permanecido asintom谩tico sin presentar recurrencia de la pancreatitis autoinmune ni de la fibrosis retroperitoneal.\\n\\n</td>\n",
       "      <td>[d49]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   texto  \\\n",
       "archivo                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "S1130-01082008001000010-1  Var贸n de 43 a帽os originario de Marruecos, que ingres贸 en nuestro servicio por cuadro de 4 d铆as de evoluci贸n de ictericia mucocut谩nea indolora, coluria y prurito generalizado. Como 煤nicos antecedentes de inter茅s destacaban una tuberculosis tratada, hipercolesterolemia en tratamiento diet茅tico y tabaquismo leve. La anal铆tica mostr贸 los siguientes datos: bilirrubina 19,44 mg/dl, GOT 110 UI/ml, GPT 371 UI/ml, GGT 632 UI/ml, FA 787 UI/ml, LDH 394 UI/ml. Amilasa y lipasa fueron normales en todo momento. Destacaba tambi茅n una hipergammaglobulinemia (gammaglobulina 1,56%), con IgG 1840 UI/ml (751-1.560 UI/ml). El marcador CA 19-9 era de 82 UI/ml. Los autoanticuerpos (ANA, AMA, AMA-2, ANCA, LKM1, SMA, SLA y F-actina) y serolog铆as para virus y bacterias (VHA, VHB, VHC, HIV, CMV, VEB, VVZ, VHS, virus de la parotidis, parvovirus B19, Brucella, Borrelia, Coxiella, Leishmania, Rickettsias y Toxoplasma) fueron negativos. La ecograf铆a abdominal mostr贸 dilataci贸n de la v铆a biliar intra- y extrahep谩tica y la ecoendoscopia (USE) un p谩ncreas aumentado de tama帽o con una lesi贸n focal de 3 cm a nivel de cabeza y leve dilataci贸n posterior del conducto pancre谩tico. La TAC toracoabdominal objetiv贸 adem谩s un p谩ncreas aumentado globalmente de tama帽o, hipodenso, con un halo peripancre谩tico hipodenso, con borde liso, sin afectaci贸n de la grasa peripancre谩tica, y, a nivel retroperitoneal, en localizaci贸n peria贸rtica con extensi贸n a territorio iliaco bilateral, un tejido denso rodeando dichas estructuras vasculares como un estuche, siendo todo ello compatible con pancreatitis autoinmune con fibrosis retroperitoneal. Ante la persistencia de prurito y la colestasis manifiesta se realiz贸 un drenaje biliar percut谩neo mostrando la colangiograf铆a una lesi贸n estenosante en col茅doco distal sugerente de neoplasia pancre谩tica. Ante dicha posibilidad como primer diagn贸stico diferencial, se realiz贸 una punci贸n-aspiraci贸n con aguja fina guiada por USE con citolog铆a negativa para c茅lulas malignas y tinci贸n Zielh negativa. Dada la ausencia de confirmaci贸n de neoplasia, y con la sospecha de pancreatitis autoinmune, se realiz贸 una colangiopancreatograf铆a retr贸grada endosc贸pica (CPRE) observando dilataci贸n de la v铆a biliar principal con una estenosis regular en su porci贸n distal, de unos 3-4 cm, de aspecto benigno, sobre la que se coloc贸 una endopr贸tesis pl谩stica. Se inici贸 tratamiento con corticoides (metilprednisolona a dosis de 32 mg/d铆a) y se retir贸 el drenaje percut谩neo. Con el diagn贸stico de probable PAI el paciente fue dado de alta y seguido de forma ambulatoria comprobando normalizaci贸n de todos los par谩metros anal铆ticos y la resoluci贸n en la TAC abdominal de control, al mes y a los 4 meses, de las lesiones descritas inicialmente, con normalizaci贸n del tama帽o y aspecto pancre谩tico y desaparici贸n de la fibrosis retroperitoneal. La dosis de corticoides fue disminuy茅ndose progresivamente hasta su retirada completa al 4潞 mes, retir谩ndose tambi茅n la endopr贸tesis biliar. Hasta la fecha actual, tras 24 meses de seguimiento, el paciente ha permanecido asintom谩tico sin presentar recurrencia de la pancreatitis autoinmune ni de la fibrosis retroperitoneal.\\n\\n   \n",
       "\n",
       "                          codigos  \n",
       "archivo                            \n",
       "S1130-01082008001000010-1   [d49]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc77de8-8256-4653-9de0-690dacc58095",
   "metadata": {},
   "source": [
    "### Conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6a6ad4",
   "metadata": {},
   "source": [
    "Repetimos algo similar, pero ahora no tenemos las etiquetas disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4d6ea92-47fd-462a-9067-33fdfdfd31a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192 entries, 0 to 191\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   archivo  192 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#los c贸digos est谩n en un TSV con un c贸digo por l铆nea\n",
    "test_diag = pd.read_csv(\"data/test/test.tsv\", sep = \"\\t\", header = None, names = [\"archivo\"])\n",
    "test_diag.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80ff5875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 192 entries, S0004-06142005000500011-1 to S2254-28842014000300010-1\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   texto   192 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "path = 'data/test/text_files/'\n",
    "\n",
    "corpus = []\n",
    "for f in [f for f in os.listdir(path) if f.endswith('.txt')]:\n",
    "    file = os.path.splitext(f)[0]\n",
    "    if file in test_diag['archivo'].values:\n",
    "        with open(os.path.join(path, f), encoding=\"utf8\") as text:\n",
    "            texto = text.read()\n",
    "            corpus.append({\n",
    "                'archivo': file,\n",
    "                'texto': texto\n",
    "            })\n",
    "    \n",
    "df_test = pd.DataFrame(corpus).set_index('archivo')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ae159e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archivo</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0004-06142007000900012-1</th>\n",
       "      <td>Mujer de 67 a帽os de edad con antecedentes personales de apendicectom铆a, hernia discal y de hiato, fractura de tibia y peron茅, as铆 como c贸lico nefr铆tico derecho que acude a consulta de urolog铆a para revisi贸n. En el estudio ecogr谩fico, se observa una neoformaci贸n s贸lida en ri帽贸n derecho de 5 cm.; se realiza TAC en el que se describe una masa a nivel cortical de ri帽贸n derecho, de aproximadamente 5 cm, de bordes externos lobulados, que no parece afectar al espacio perirrenal, no observ谩ndose adenopat铆as, ni dilataci贸n de v铆a renal excretora. Con el diagn贸stico de probable hipernefroma se realiza nefrectom铆a radical derecha mediante laparoscopia.\\n\\nEn el estudio macrosc贸pico se describe una neoformaci贸n cortical de 5 cm de di谩metro m谩ximo, bien delimitada, pero no encapsulada, que deforma la superficie cortical sin atravesarla, con una superficie de corte de coloraci贸n amarillenta con 谩reas de aspecto hemorr谩gicas y 谩reas qu铆sticas.\\nEn el estudio microsc贸pico la neoformaci贸n est谩 constituida por estructuras acinares tapizadas por peque帽as c茅lulas cuboidales uniformes, con escaso citoplasma y n煤cleos con cromatina uniforme, inmersas en un estroma ligeramente celular. Se realiz贸 estudio inmunohistoqu铆mico para determinaci贸n de vimentina, citoqueratina 7, citoqueratina de amplio espectro, CD34, cromogranina y EMA (Master Diagnostic. Granada. Espa帽a), observ谩ndose expresi贸n generalizada de vimentina, focal de citoqueraina 7 y EMA en las c茅lulas epiteliales, y CD34 en el componente estromal.\\n\\nLa paciente cursa tras la intervenci贸n sin incidentes destacables y se encuentra asintom谩tica a los 24 meses de la intervenci贸n.\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  texto\n",
       "archivo                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "S0004-06142007000900012-1  Mujer de 67 a帽os de edad con antecedentes personales de apendicectom铆a, hernia discal y de hiato, fractura de tibia y peron茅, as铆 como c贸lico nefr铆tico derecho que acude a consulta de urolog铆a para revisi贸n. En el estudio ecogr谩fico, se observa una neoformaci贸n s贸lida en ri帽贸n derecho de 5 cm.; se realiza TAC en el que se describe una masa a nivel cortical de ri帽贸n derecho, de aproximadamente 5 cm, de bordes externos lobulados, que no parece afectar al espacio perirrenal, no observ谩ndose adenopat铆as, ni dilataci贸n de v铆a renal excretora. Con el diagn贸stico de probable hipernefroma se realiza nefrectom铆a radical derecha mediante laparoscopia.\\n\\nEn el estudio macrosc贸pico se describe una neoformaci贸n cortical de 5 cm de di谩metro m谩ximo, bien delimitada, pero no encapsulada, que deforma la superficie cortical sin atravesarla, con una superficie de corte de coloraci贸n amarillenta con 谩reas de aspecto hemorr谩gicas y 谩reas qu铆sticas.\\nEn el estudio microsc贸pico la neoformaci贸n est谩 constituida por estructuras acinares tapizadas por peque帽as c茅lulas cuboidales uniformes, con escaso citoplasma y n煤cleos con cromatina uniforme, inmersas en un estroma ligeramente celular. Se realiz贸 estudio inmunohistoqu铆mico para determinaci贸n de vimentina, citoqueratina 7, citoqueratina de amplio espectro, CD34, cromogranina y EMA (Master Diagnostic. Granada. Espa帽a), observ谩ndose expresi贸n generalizada de vimentina, focal de citoqueraina 7 y EMA en las c茅lulas epiteliales, y CD34 en el componente estromal.\\n\\nLa paciente cursa tras la intervenci贸n sin incidentes destacables y se encuentra asintom谩tica a los 24 meses de la intervenci贸n.\\n\\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b472f280-db6a-438d-8340-f7b19758399b",
   "metadata": {},
   "source": [
    "### Binarizar las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae41be51-448e-433b-b10f-b4236afbaa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# para entrenar un clasificador multi-etiqueta generamos una matriz binaria de las etiquetas\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(df_train['codigos'])\n",
    "\n",
    "#Guardamos las clases utilizadas en el conjunto de train\n",
    "clases = mlb.classes_\n",
    "num_classes = clases.shape\n",
    "print(num_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f59c35",
   "metadata": {},
   "source": [
    "## Procesamiento del lenguaje natural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de409c67",
   "metadata": {},
   "source": [
    "En esta secci贸n se llevar谩 a cabo el procesamiento de los textos provenientes de las historias cl铆nicas usando t茅cnicas de NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f1e21",
   "metadata": {},
   "source": [
    "Con la librer铆a de spacy cargamos el modelo `es_core_news_lg` de Spacy. El sufijo *lg* indica que es un modelo de tama帽o grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53ed5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download es_core_news_lg\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cdde5f",
   "metadata": {},
   "source": [
    "### BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049e3c4d",
   "metadata": {},
   "source": [
    "El enfoque Bag of Words (BoW) es una t茅cnica simple pero efectiva utilizada en el procesamiento de lenguaje natural para representar documentos de texto como vectores num茅ricos. La idea detr谩s de BoW es tratar cada documento como un \"saco\" de palabras, sin tener en cuenta el orden en que aparecen las palabras en el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeb61cb",
   "metadata": {},
   "source": [
    "Obtenemos resultados ligeramente mejores sin realizar un preprocesamiento con la funci贸n `normalizeDoc()` previamente a la aplicaci贸n del *Bag of Words*. La adici贸n de *n-grams* empeora los resultados de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb424683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_trainText = [normalizeDoc(nlp, doc) for doc in df_train['texto'].values]\n",
    "x_trainText = df_train['texto'].values\n",
    "x_testText = df_test['texto'].values\n",
    "\n",
    "vectorizer = CountVectorizer() # para el bag of words, de sklearn\n",
    "x_trainArray = vectorizer.fit_transform(x_trainText) # matriz tipo sparse\n",
    "x_testArray = vectorizer.transform(x_testText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b7b747",
   "metadata": {},
   "source": [
    "Las matrices sparse `x_trainArray` y `x_testArray` contienen los recuentos de palabras del BoW para train y test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b0d0d",
   "metadata": {},
   "source": [
    "## Modelos (usando `es_core_news_lg`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e74155",
   "metadata": {},
   "source": [
    "Empezamos dividiendo nuestro conjunto de training en dos subconjuntos, que nos permitan distinguir entre lo que ser铆a el conjunto de training y el de testing. Estrictamente, es un conjunto de validaci贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9f9be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train_train, y_train_test = train_test_split(x_trainArray, y_train, test_size = 0.1, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d49be3",
   "metadata": {},
   "source": [
    "### Nuestro mejor modelo: MultiOutput con GradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc7f992",
   "metadata": {},
   "source": [
    "Se aplica un modelo de clasificaci贸n conocido como **Gradient Boosting Classifier**, el cual es una t茅cnica de ensemble learning que combina m煤ltiples modelos de 谩rboles de decisi贸n d茅biles para construir un modelo m谩s robusto y preciso. Este modelo se caracteriza por ajustar secuencialmente nuevos 谩rboles de decisi贸n a los residuos del modelo anterior, lo que permite mejorar gradualmente la predicci贸n. En este caso particular, se utilizar谩 una variante del Gradient Boosting Classifier con una funci贸n de p茅rdida exponencial y se configurar谩n varios hiperpar谩metros, como el n煤mero de estimadores, la profundidad m谩xima del 谩rbol y el n煤mero m铆nimo de muestras requeridas para dividir un nodo.\n",
    "\n",
    "Con el **MultiOutputClassifier** tendremos un clasificador por target. Esta es una estrategia simple para extender clasificadores que de manera nativa no soportan una clasificaci贸n multi-output.\n",
    "\n",
    " Una vez que el modelo est茅 entrenado, se evaluar谩 su rendimiento utilizando m茅tricas como la precisi贸n, el recall y el puntaje F1 a trav茅s de un informe de clasificaci贸n.\n",
    "\n",
    "Informaci贸n `GradientBoostingClassifier()`: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html.\n",
    "\n",
    "Informaci贸n `MultiOutputClassifier()`: https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f2927cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 17317)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f35a7005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.62      0.73        13\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      0.75      0.86         8\n",
      "           3       0.80      0.57      0.67        14\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      0.93      0.97        15\n",
      "           6       1.00      0.31      0.47        13\n",
      "           7       1.00      0.92      0.96        12\n",
      "           8       0.88      0.88      0.88         8\n",
      "           9       1.00      1.00      1.00        17\n",
      "\n",
      "   micro avg       0.96      0.80      0.87       124\n",
      "   macro avg       0.96      0.80      0.85       124\n",
      "weighted avg       0.96      0.80      0.85       124\n",
      " samples avg       0.92      0.82      0.85       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = GradientBoostingClassifier(loss = 'exponential', n_estimators = 50, max_depth = 5, min_samples_split = 5, random_state = seed)\n",
    "model = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "model.fit(x_train, y_train_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0) # zero_division = 0 para evitar warnings\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6c3f68",
   "metadata": {},
   "source": [
    "Vemos que obtenemos un f1-score de 0.85 en la versi贸n `weighted` para el conjunto de validaci贸n que hab铆amos previamente establecido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11916ec",
   "metadata": {},
   "source": [
    "### Coseno similitud (*manual*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaff3c0",
   "metadata": {},
   "source": [
    "En esta subsecci贸n se usa una t茅cnica de similitud coseno manual para encontrar los documentos m谩s similares dentro del conjunto de entrenamiento en relaci贸n con los documentos del conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c275e5",
   "metadata": {},
   "source": [
    "Hacemos primeramente una divisi贸n para los textos tambi茅n, al igual que hicimos anteriormente con las matrices sparse (mantenemos mismo random_state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8476ec88-d3f6-477f-8cc9-d298ce8077b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTag = df_train.index.values \n",
    "\n",
    "x_trainT, x_testT, xTag_train, xTag_test = train_test_split(x_trainText, xTag, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0689372a-2ed7-45d5-895c-92b4f773c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "x_trainVec = vectorizer.fit_transform(x_trainT)\n",
    "x_trainVecDf = pd.DataFrame(x_trainVec.toarray(), columns = vectorizer.get_feature_names_out(), index = xTag_train)\n",
    "\n",
    "x_testVec = vectorizer.transform(x_testT)\n",
    "x_testVecDf = pd.DataFrame(x_testVec.toarray(), columns = vectorizer.get_feature_names_out(), index = xTag_test)\n",
    "\n",
    "similarity = cosine_similarity(x_testVecDf, x_trainVecDf)\n",
    "similarityDf = pd.DataFrame(similarity, index = x_testVecDf.index, columns = x_trainVecDf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8e24959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>archivoMostSimilar</th>\n",
       "      <th>similarity</th>\n",
       "      <th>codigosPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0210-48062010000100019-4</th>\n",
       "      <td>S0210-48062009000900017-1</td>\n",
       "      <td>0.723986</td>\n",
       "      <td>[d49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1134-80462015000200005-1</th>\n",
       "      <td>S0376-78922016000200012-1</td>\n",
       "      <td>0.877009</td>\n",
       "      <td>[r69, d49, i10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1139-76322009000400007-1</th>\n",
       "      <td>S1698-69462006000400005-1</td>\n",
       "      <td>0.829529</td>\n",
       "      <td>[n28, d49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0376-78922014000100013-1</th>\n",
       "      <td>S0376-78922016000200012-1</td>\n",
       "      <td>0.878946</td>\n",
       "      <td>[r69, d49, i10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1130-01082007001100012-1</th>\n",
       "      <td>S0212-16112010000100017-1</td>\n",
       "      <td>0.690295</td>\n",
       "      <td>[r60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  archivoMostSimilar similarity  \\\n",
       "S0210-48062010000100019-4  S0210-48062009000900017-1   0.723986   \n",
       "S1134-80462015000200005-1  S0376-78922016000200012-1   0.877009   \n",
       "S1139-76322009000400007-1  S1698-69462006000400005-1   0.829529   \n",
       "S0376-78922014000100013-1  S0376-78922016000200012-1   0.878946   \n",
       "S1130-01082007001100012-1  S0212-16112010000100017-1   0.690295   \n",
       "\n",
       "                               codigosPred  \n",
       "S0210-48062010000100019-4            [d49]  \n",
       "S1134-80462015000200005-1  [r69, d49, i10]  \n",
       "S1139-76322009000400007-1       [n28, d49]  \n",
       "S0376-78922014000100013-1  [r69, d49, i10]  \n",
       "S1130-01082007001100012-1            [r60]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilarDf = findMostSimilar(similarityDf, df_train)\n",
    "\n",
    "mostSimilarDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1d8d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al menos 1 coincidencia: 0.4397163120567376\n",
      "Accuracy media: 0.2504728132387707\n"
     ]
    }
   ],
   "source": [
    "mostSimilarDf = checkAccuracy(mostSimilarDf, df_train)\n",
    "print(f\"Al menos 1 coincidencia: {(mostSimilarDf['guess'] != 0).sum() / mostSimilarDf.shape[0]}\")\n",
    "print(f\"Accuracy media: {mostSimilarDf['guess'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651e603",
   "metadata": {},
   "source": [
    "### Otros modelos de clasificaci贸n multietiqueta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef20299",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da121c0",
   "metadata": {},
   "source": [
    "El modelo de Random Forest es una t茅cnica de aprendizaje autom谩tico que se basa en la construcci贸n de m煤ltiples 谩rboles de decisi贸n durante el proceso de entrenamiento y combina sus predicciones para obtener una predicci贸n final. Cada 谩rbol en el bosque se entrena de forma independiente utilizando un subconjunto aleatorio de las caracter铆sticas y las muestras del conjunto de entrenamiento, lo que fomenta la diversidad entre los 谩rboles y ayuda a reducir el sobreajuste.\n",
    "\n",
    "Una de las caracter铆sticas clave del modelo de Random Forest es su capacidad para manejar problemas de m煤ltiples salidas o multioutput."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aca665",
   "metadata": {},
   "source": [
    "Hemos comprobado que aumentar el n煤mero de estimadores, `n_estimators` disminuye dr谩sticamente los resultados. Es por eso que tenemos un n煤mero bajo. \n",
    "Por otra parte, el criterio `criterion` no parece afectar de manera significativa a los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a176f20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.08      0.12        13\n",
      "           1       0.86      0.38      0.52        16\n",
      "           2       0.50      0.12      0.20         8\n",
      "           3       0.50      0.29      0.36        14\n",
      "           4       0.75      0.38      0.50         8\n",
      "           5       0.50      0.33      0.40        15\n",
      "           6       0.36      0.31      0.33        13\n",
      "           7       0.60      0.25      0.35        12\n",
      "           8       0.50      0.12      0.20         8\n",
      "           9       0.33      0.12      0.17        17\n",
      "\n",
      "   micro avg       0.51      0.24      0.33       124\n",
      "   macro avg       0.52      0.24      0.32       124\n",
      "weighted avg       0.51      0.24      0.32       124\n",
      " samples avg       0.36      0.26      0.28       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_target_classifier = RandomForestClassifier(n_estimators = 3, criterion = 'gini', n_jobs = 4, random_state = seed)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0483d1f",
   "metadata": {},
   "source": [
    "La semilla `random_state` depende enormemente de los resultados que se obtienen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380064f",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0225c0a6",
   "metadata": {},
   "source": [
    "El MLPClassifier, que representa el Perceptr贸n Multicapa (Multilayer Perceptron) en la biblioteca scikit-learn, es una poderosa herramienta de aprendizaje supervisado utilizada para la clasificaci贸n. Basado en redes neuronales artificiales, el MLPClassifier es conocido por su capacidad para modelar relaciones complejas entre las caracter铆sticas de entrada y las etiquetas de salida en conjuntos de datos.\n",
    "\n",
    "Al aprovechar una arquitectura de red neuronal con m煤ltiples capas de nodos interconectados, el MLPClassifier puede aprender patrones no lineales en los datos.\n",
    "\n",
    "M谩s informaci贸n: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc9c39",
   "metadata": {},
   "source": [
    "Usamos el optimizador `Adam` ya que generalmente es el que mejores resultados ofrece. Las redes neuronales por construcci贸n tambi茅n van a admitir f谩cilmente una clasificaci贸n multi-output. `MLPClassifier` gestiona eso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "723f59cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.14        13\n",
      "           1       0.50      0.06      0.11        16\n",
      "           2       1.00      0.50      0.67         8\n",
      "           3       1.00      0.21      0.35        14\n",
      "           4       0.50      0.12      0.20         8\n",
      "           5       0.80      0.27      0.40        15\n",
      "           6       0.50      0.15      0.24        13\n",
      "           7       1.00      0.33      0.50        12\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       1.00      0.12      0.21        17\n",
      "\n",
      "   micro avg       0.79      0.18      0.29       124\n",
      "   macro avg       0.73      0.19      0.28       124\n",
      "weighted avg       0.76      0.18      0.28       124\n",
      " samples avg       0.30      0.18      0.21       124\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "multi_target_classifier = MLPClassifier(activation = 'relu', solver = 'adam', max_iter = 1000, random_state = seed)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd551adb",
   "metadata": {},
   "source": [
    "#### MultiOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915b4c7b",
   "metadata": {},
   "source": [
    "Se muestran a continuaci贸n otros resultados con clasificadores a los que se les a帽ade la funcionalidad que proporciona `MultiOutputClassifier`.\n",
    "\n",
    "Con este se hace un ajuste de un clasificador por cada *target*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628531d0",
   "metadata": {},
   "source": [
    "##### Regression Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6a983",
   "metadata": {},
   "source": [
    "La clase `LogisticRegression()` en scikit-learn es una implementaci贸n del algoritmo de regresi贸n log铆stica, tambi茅n conocido como logit o MaxEnt, que se utiliza principalmente para problemas de clasificaci贸n binaria y multiclase. Este algoritmo modela la relaci贸n entre una variable dependiente categ贸rica y una o m谩s variables independientes mediante el uso de la funci贸n log铆stica para predecir la probabilidad de que una observaci贸n pertenezca a una determinada categor铆a.\n",
    "\n",
    "La clase ofrece una variedad de opciones para personalizar el modelo, como la especificaci贸n del tipo de penalizaci贸n, el ajuste de la regularizaci贸n, la elecci贸n del solver para la optimizaci贸n, entre otros.\n",
    "\n",
    "M谩s informaci贸n: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "091125fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.23      0.35        13\n",
      "           1       1.00      0.25      0.40        16\n",
      "           2       0.64      0.88      0.74         8\n",
      "           3       0.71      0.36      0.48        14\n",
      "           4       0.38      0.38      0.38         8\n",
      "           5       0.67      0.27      0.38        15\n",
      "           6       0.43      0.23      0.30        13\n",
      "           7       0.75      0.50      0.60        12\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.91      0.59      0.71        17\n",
      "\n",
      "   micro avg       0.67      0.36      0.47       124\n",
      "   macro avg       0.62      0.37      0.43       124\n",
      "weighted avg       0.68      0.36      0.45       124\n",
      " samples avg       0.51      0.33      0.39       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = LogisticRegression(penalty = 'l2', solver = 'newton-cg', max_iter = 1000,\n",
    "                                     multi_class = 'multinomial', random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "417a9432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.31      0.40        13\n",
      "           1       0.80      0.50      0.62        16\n",
      "           2       0.64      0.88      0.74         8\n",
      "           3       0.70      0.50      0.58        14\n",
      "           4       0.29      0.25      0.27         8\n",
      "           5       0.75      0.40      0.52        15\n",
      "           6       0.56      0.38      0.45        13\n",
      "           7       0.78      0.58      0.67        12\n",
      "           8       0.50      0.12      0.20         8\n",
      "           9       0.89      0.47      0.62        17\n",
      "\n",
      "   micro avg       0.67      0.44      0.53       124\n",
      "   macro avg       0.65      0.44      0.51       124\n",
      "weighted avg       0.68      0.44      0.52       124\n",
      " samples avg       0.58      0.46      0.48       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = PassiveAggressiveClassifier(random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "102daac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.31      0.36        13\n",
      "           1       0.80      0.25      0.38        16\n",
      "           2       0.47      0.88      0.61         8\n",
      "           3       0.56      0.36      0.43        14\n",
      "           4       0.14      0.12      0.13         8\n",
      "           5       0.86      0.40      0.55        15\n",
      "           6       0.42      0.38      0.40        13\n",
      "           7       0.60      0.75      0.67        12\n",
      "           8       0.40      0.25      0.31         8\n",
      "           9       0.75      0.53      0.62        17\n",
      "\n",
      "   micro avg       0.54      0.42      0.47       124\n",
      "   macro avg       0.54      0.42      0.45       124\n",
      "weighted avg       0.59      0.42      0.46       124\n",
      " samples avg       0.51      0.44      0.44       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = SGDClassifier(loss = 'squared_hinge', penalty = 'elasticnet', random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b696cc",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc2e11b",
   "metadata": {},
   "source": [
    "Introducimos ahora para nuestro modelo de `RandomForestClassifier` un acople con `MultiOutputClassifier` para tener un enfoque de uno en uno para cada *target*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9781407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.31      0.42        13\n",
      "           1       0.86      0.75      0.80        16\n",
      "           2       0.50      0.38      0.43         8\n",
      "           3       0.62      0.36      0.45        14\n",
      "           4       0.50      0.25      0.33         8\n",
      "           5       1.00      0.33      0.50        15\n",
      "           6       0.42      0.38      0.40        13\n",
      "           7       0.64      0.75      0.69        12\n",
      "           8       1.00      0.12      0.22         8\n",
      "           9       0.71      0.29      0.42        17\n",
      "\n",
      "   micro avg       0.66      0.41      0.51       124\n",
      "   macro avg       0.69      0.39      0.47       124\n",
      "weighted avg       0.70      0.41      0.49       124\n",
      " samples avg       0.46      0.34      0.37       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = RandomForestClassifier(n_estimators = 3, random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c74db",
   "metadata": {},
   "source": [
    "Vemos que obtenemos mejores resultados que en el caso anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67683bd",
   "metadata": {},
   "source": [
    "##### K-Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c87a7",
   "metadata": {},
   "source": [
    "`KNeighborsClassifier` es un clasificador de vecinos m谩s cercanos implementado en scikit-learn que se utiliza para problemas de clasificaci贸n supervisada. Este algoritmo clasifica las instancias de datos bas谩ndose en la similitud con los ejemplos de entrenamiento m谩s cercanos en el espacio de caracter铆sticas. Espec铆ficamente, asigna una etiqueta a una nueva instancia seg煤n la mayor铆a de votos de sus k vecinos m谩s cercanos, donde k es un par谩metro definido por el usuario. `KNeighborsClassifier` es f谩cil de entender e implementar, y es especialmente 煤til para conjuntos de datos peque帽os o medianos donde la relaci贸n entre las caracter铆sticas y las etiquetas es no lineal. Antes de utilizar este clasificador, es importante ajustar adecuadamente el valor de k y comprender c贸mo afecta al rendimiento del modelo en diferentes conjuntos de datos.\n",
    "\n",
    "M谩s informaci贸n: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a2579a",
   "metadata": {},
   "source": [
    "Los mejores resultados apreciados se obtienen con `n_neighbors = 3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71199765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.15      0.25        13\n",
      "           1       0.38      0.19      0.25        16\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.75      0.21      0.33        14\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.00      0.00      0.00        15\n",
      "           6       0.44      0.31      0.36        13\n",
      "           7       0.40      0.33      0.36        12\n",
      "           8       0.50      0.38      0.43         8\n",
      "           9       0.50      0.29      0.37        17\n",
      "\n",
      "   micro avg       0.41      0.19      0.26       124\n",
      "   macro avg       0.36      0.19      0.24       124\n",
      "weighted avg       0.39      0.19      0.25       124\n",
      " samples avg       0.32      0.20      0.23       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32f52e",
   "metadata": {},
   "source": [
    "De todas formas, los resultados no son buenos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5c074",
   "metadata": {},
   "source": [
    "##### Gradient Boosting: Grid Search (mejor modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7bd242",
   "metadata": {},
   "source": [
    "`GridSearchCV`, que significa Validaci贸n Cruzada con B煤squeda de Cuadr铆cula, es una t茅cnica de b煤squeda de hiperpar谩metros exhaustiva que se utiliza para encontrar la combinaci贸n 贸ptima de hiperpar谩metros para un modelo de aprendizaje autom谩tico. Funciona evaluando sistem谩ticamente todas las combinaciones posibles de valores de hiperpar谩metros especificados en una cuadr铆cula predefinida. Para cada combinaci贸n de hiperpar谩metros, `GridSearchCV` utiliza la validaci贸n cruzada para evaluar el rendimiento del modelo en m煤ltiples divisiones del conjunto de datos de entrenamiento, lo que ayuda a mitigar el riesgo de sobreajuste. Al finalizar la b煤squeda, devuelve la combinaci贸n de hiperpar谩metros que produce el mejor rendimiento seg煤n una m茅trica especificada, como precisi贸n, puntuaci贸n F1 o alguna otra medida de rendimiento.\n",
    "\n",
    "`GridSearchCV` es una herramienta poderosa para optimizar los modelos de aprendizaje autom谩tico, ya que automatiza el proceso de ajuste de hiperpar谩metros y ayuda a encontrar la configuraci贸n que maximiza el rendimiento del modelo en datos no vistos.\n",
    "\n",
    "M谩s informaci贸n: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "59e6add7-769c-40b6-931b-1fca0721a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters: {'estimator__max_depth': 7, 'estimator__min_samples_split': 2, 'estimator__n_estimators': 60}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.38      0.45        13\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       0.60      0.75      0.67         8\n",
      "           3       0.89      0.57      0.70        14\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      0.93      0.97        15\n",
      "           6       0.80      0.31      0.44        13\n",
      "           7       1.00      0.92      0.96        12\n",
      "           8       0.88      0.88      0.88         8\n",
      "           9       1.00      1.00      1.00        17\n",
      "\n",
      "   micro avg       0.90      0.77      0.83       124\n",
      "   macro avg       0.87      0.77      0.81       124\n",
      "weighted avg       0.89      0.77      0.81       124\n",
      " samples avg       0.88      0.80      0.81       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = GradientBoostingClassifier(loss = 'exponential', random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [40, 50, 60],\n",
    "    'estimator__max_depth': [3, 5, 7],\n",
    "    'estimator__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
    "\n",
    "grid_search = GridSearchCV(multi_target_classifier, param_grid, cv = 5, scoring = f1_scorer, n_jobs = 4, verbose = 1)\n",
    "grid_search.fit(x_train, y_train_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_estimator = grid_search.best_estimator_\n",
    "best_estimator.fit(x_train, y_train_train)\n",
    "\n",
    "y_pred = best_estimator.predict(x_test)\n",
    "\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9846b1",
   "metadata": {},
   "source": [
    "Intentamos mejorar el modelo a帽adiendo un `AdaBoostClassifier` para mejorar el *fitting* del estimador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130b2b9",
   "metadata": {},
   "source": [
    "`AdaBoostClassifier` es un algoritmo de aprendizaje autom谩tico que se utiliza com煤nmente para la clasificaci贸n. Es un tipo de algoritmo de conjunto que combina m煤ltiples modelos de aprendizaje d茅biles para crear un modelo fuerte. El principio b谩sico detr谩s de AdaBoost es entrenar iterativamente una secuencia de clasificadores d茅biles, donde cada clasificador se enfoca en las instancias que los clasificadores anteriores clasificaron incorrectamente. En cada iteraci贸n, se da m谩s peso a las instancias clasificadas incorrectamente para que el pr贸ximo clasificador se centre en corregir esos errores. \n",
    "\n",
    "Al final del proceso, los clasificadores d茅biles se combinan mediante votaci贸n ponderada para formar un clasificador fuerte. AdaBoost es efectivo en una variedad de problemas de clasificaci贸n y es especialmente 煤til cuando se utilizan clasificadores simples como base, como 谩rboles de decisi贸n con poca profundidad.\n",
    "\n",
    "M谩s informaci贸n: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a4bdeabe-13e4-48f6-bc3c-0538b3394303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.46      0.60        13\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      0.75      0.86         8\n",
      "           3       0.80      0.57      0.67        14\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      0.93      0.97        15\n",
      "           6       1.00      0.38      0.56        13\n",
      "           7       1.00      0.92      0.96        12\n",
      "           8       0.88      0.88      0.88         8\n",
      "           9       1.00      1.00      1.00        17\n",
      "\n",
      "   micro avg       0.96      0.79      0.87       124\n",
      "   macro avg       0.95      0.79      0.85       124\n",
      "weighted avg       0.95      0.79      0.85       124\n",
      " samples avg       0.88      0.79      0.82       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator = GradientBoostingClassifier(loss = 'exponential', criterion = 'friedman_mse', n_estimators = 50, max_depth = 5, min_samples_split = 5, random_state = seed)\n",
    "base_classifier = AdaBoostClassifier(estimator = estimator, n_estimators = 100, random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29487b3a",
   "metadata": {},
   "source": [
    "Los resultados mejoraron ligeramente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838794ad",
   "metadata": {},
   "source": [
    "##### Light Gradient-Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a16f0b",
   "metadata": {},
   "source": [
    "El Light Gradient Boosting Classifier (LightGBM) es una poderosa implementaci贸n de algoritmo de aumento de gradiente que se destaca por su eficiencia y rendimiento en conjuntos de datos grandes. Utiliza una estrategia de construcci贸n de 谩rboles en hojas, lo que significa que se construyen los nodos hoja primero y luego se dividen hacia atr谩s. Esto reduce significativamente el consumo de memoria y acelera el tiempo de entrenamiento. LightGBM tambi茅n utiliza una t茅cnica de muestreo por gradiente para seleccionar los mejores nodos hoja, lo que mejora la precisi贸n del modelo y lo hace altamente escalable. Adem谩s, proporciona una variedad de par谩metros para la personalizaci贸n del modelo y es ampliamente utilizado en problemas de clasificaci贸n y regresi贸n en la pr谩ctica de aprendizaje autom谩tico.\n",
    "\n",
    "M谩s informaci贸n: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e693b9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.58        13\n",
      "           1       0.92      0.75      0.83        16\n",
      "           2       0.71      0.62      0.67         8\n",
      "           3       0.88      0.50      0.64        14\n",
      "           4       1.00      0.75      0.86         8\n",
      "           5       1.00      0.80      0.89        15\n",
      "           6       0.88      0.54      0.67        13\n",
      "           7       1.00      0.83      0.91        12\n",
      "           8       0.88      0.88      0.88         8\n",
      "           9       1.00      1.00      1.00        17\n",
      "\n",
      "   micro avg       0.90      0.73      0.80       124\n",
      "   macro avg       0.89      0.72      0.79       124\n",
      "weighted avg       0.90      0.73      0.80       124\n",
      " samples avg       0.78      0.73      0.73       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = lgb.LGBMClassifier(boosting_type = 'dart', n_estimators = 50, objective = 'binary', random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train.astype(np.float32), y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test.astype(np.float32))\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356c0fe",
   "metadata": {},
   "source": [
    "Los resultados que obtenemos son algo inferiores que en el modelo de `GradientBoostingClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c7119e-b68d-447f-ae89-ef18c223ebf8",
   "metadata": {},
   "source": [
    "## Guardar predicciones de Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0121e",
   "metadata": {},
   "source": [
    "En esta secci贸n se implementa el c贸digo para predicci贸n en nuestro conjunto de `testing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6167ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_testArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89cd23",
   "metadata": {},
   "source": [
    "### Etiquetado de textos sin etiqueta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe47a92",
   "metadata": {},
   "source": [
    "#### Asignaci贸n de la etiqueta m谩s probable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53288e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-labeled texts: [ 84  85  91  92 108 138 139 140 155 168 169 189]\n"
     ]
    }
   ],
   "source": [
    "zeroIdx = np.where(np.sum(y_test_pred, axis = 1) == 0)[0] # los que tienen todas las etiquetas a 0\n",
    "if zeroIdx.size > 0:\n",
    "    print('Non-labeled texts:', zeroIdx)\n",
    "    probs = model.predict_proba(x_testArray) # probabilidades de cada clase\n",
    "    for idx in zeroIdx:\n",
    "        oneProb = []\n",
    "        for probArray, classes in zip(probs, model.classes_):\n",
    "            p = probArray[idx][classes == 1][0] \n",
    "            oneProb.append(p)\n",
    "        y_test_pred[idx, np.argmax(oneProb)] = 1 # se asigna la clase con prob m谩s alta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ff4d4",
   "metadata": {},
   "source": [
    "#### Active-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbcaa1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainStack = x_train\n",
    "y_trainStack = y_train_train\n",
    "x_testStack = x_testArray\n",
    "y_predStack = y_test_pred\n",
    "\n",
    "zeroIdx = np.where(np.sum(y_predStack, axis = 1) == 0)[0]\n",
    "nZeros = []\n",
    "while zeroIdx.size > 0: # hasta que ya no haya muestras sin etiquetar\n",
    "\n",
    "    model.fit(x_trainStack, y_trainStack)\n",
    "    y_predStack = model.predict(x_testStack)\n",
    "\n",
    "    zeroIdx = np.where(np.sum(y_predStack, axis = 1) == 0)[0]\n",
    "    nZeros.append(zeroIdx.size)\n",
    "\n",
    "    print(x_trainStack.shape, x_testStack.shape, nZeros)\n",
    "\n",
    "    # Si n煤mero de muestras sin etiquetar es igual en las 煤ltimas 3 iteraciones, se detiene\n",
    "    if len(nZeros) >= 3 and (nZeros[-1] == nZeros[-2] == nZeros[-3]):\n",
    "        raise Exception('Active Learning could not label any sample in the last 2 iterations. Quitting...')\n",
    "\n",
    "    x_lab = x_testStack[[i for i in range(x_testStack.shape[0]) if i not in zeroIdx]]\n",
    "    x_testStack = x_testStack[zeroIdx]\n",
    "\n",
    "    y_lab = y_predStack[[i for i in range(y_predStack.shape[0]) if i not in zeroIdx]]\n",
    "\n",
    "    x_trainStack = vstack([x_trainStack, x_lab])\n",
    "    y_trainStack = np.vstack([y_trainStack, y_lab])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0775823c",
   "metadata": {},
   "source": [
    "### Escritura en fichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff863c1c-9821-4ad4-a912-1abe400f5c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192 entries, 0 to 191\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   archivo  192 non-null    object\n",
      " 1   d49      192 non-null    int32 \n",
      " 2   i10      192 non-null    int32 \n",
      " 3   n28      192 non-null    int32 \n",
      " 4   r10      192 non-null    int32 \n",
      " 5   r11      192 non-null    int32 \n",
      " 6   r50      192 non-null    int32 \n",
      " 7   r52      192 non-null    int32 \n",
      " 8   r59      192 non-null    int32 \n",
      " 9   r60      192 non-null    int32 \n",
      " 10  r69      192 non-null    int32 \n",
      "dtypes: int32(10), object(1)\n",
      "memory usage: 9.1+ KB\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(y_test_pred, index = df_test.index, columns = clases)\n",
    "results.reset_index(inplace = True)\n",
    "\n",
    "results.to_csv('results/bow-multioutput-gradientboosting.csv', index = False)\n",
    "results.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eca6be9-3ab2-4756-80a0-4880568d1cd7",
   "metadata": {},
   "source": [
    "# GPTChallenge: diagnóstico a partir de HCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de358c45-755b-4fad-9d68-72e591de8b4b",
   "metadata": {},
   "source": [
    "Vamos a trabajar con el corpus CodEsp (textos de historial clínico etiquetados con sus códigos CIE-10 Diagnóstico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d4da20-1cea-4309-941f-c2440b01801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, re, spacy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import lightgbm as lgb\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9e5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDoc(nlp, doc, nMinCharacters = 0):\n",
    "    \"\"\"\n",
    "    Normaliza un texto eliminando palabras por debajo del mínimo de caracteres, stop words y números.\n",
    "    Para ello, tokeniza empleando un modelo de Spacy.\n",
    "    \"\"\"\n",
    "    # Separar en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # Filtrar tokens\n",
    "    filtered_tokens = [t.lower_ for t in tokens if (len(t.text) >= nMinCharacters) and not t.is_punct and not re.match('[0-9]+', t.text)]\n",
    "    # Recombinamos los tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return doc\n",
    "\n",
    "def findMostSimilar(similarityDf: pd.DataFrame, data: pd.DataFrame, nMostSimilars: int = 1):\n",
    "    \"\"\"\n",
    "    Encuentra la etiqueta de los documentos más similares.\n",
    "    \"\"\"\n",
    "    # Crear df de resultados\n",
    "    results = pd.DataFrame(index = similarityDf.index, columns = ['archivoMostSimilar', 'similarity', 'codigosPred'])\n",
    "\n",
    "    for index, row in similarityDf.iterrows():\n",
    "        \n",
    "        # Buscar la máxima similitud\n",
    "        mostSimilar = row.nlargest(nMostSimilars)\n",
    "        \n",
    "        results.loc[index, 'archivoMostSimilar'] = mostSimilar.index.values\n",
    "        if nMostSimilars == 1:\n",
    "            results.loc[index, 'similarity'] = mostSimilar.values[0]\n",
    "        else:\n",
    "            results.loc[index, 'similarity'] = row[mostSimilar.index]\n",
    "\n",
    "    # Coger las etiquetas\n",
    "    if nMostSimilars == 1:\n",
    "        results['codigosPred'] = data.loc[np.squeeze(np.vstack(results['archivoMostSimilar'].values)), 'codigos'].values\n",
    "    else:\n",
    "        pass\n",
    "    return results\n",
    "\n",
    "def checkAccuracy(pred: pd.DataFrame, data: pd.DataFrame):\n",
    "    pred['codigos'] = data.loc[pred.index, 'codigos']\n",
    "\n",
    "    pred['guess'] = pred.apply(\n",
    "        lambda row: len(set(row['codigosPred']).intersection(row['codigos'])) / len(row['codigosPred']),\n",
    "        axis = 1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e8803",
   "metadata": {},
   "source": [
    "## Lectura y preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c8c08",
   "metadata": {},
   "source": [
    "### Conjunto de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566a8909-46d3-4ccd-8a67-96d819f60e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8316 entries, 0 to 8315\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   archivo  8316 non-null   object\n",
      " 1   codigo   8316 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 130.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#los códigos están en un TSV con un código por línea\n",
    "train_diag = pd.read_csv(\"data/train/train.tsv\", sep=\"\\t\", header=None, names=[\"archivo\", \"codigo\"])\n",
    "train_diag.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cbd33aa-1d54-419f-a1f1-728bb03b79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "r52    163\n",
      "r10    163\n",
      "r59    160\n",
      "r69    150\n",
      "r50    144\n",
      "      ... \n",
      "c31      1\n",
      "d62      1\n",
      "s53      1\n",
      "s34      1\n",
      "n81      1\n",
      "Name: count, Length: 918, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "918"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cogemos la categoría superior de cada código y las agrupamos\n",
    "train_diag['cat'] = train_diag['codigo'].str.extract(r'(\\w\\d\\d)')\n",
    "print(train_diag['cat'].value_counts())\n",
    "train_diag['cat'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eaf143a-b460-410e-8af2-a268181153d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r52', 'r10', 'r59', 'r69', 'r50', 'r60', 'i10', 'r11', 'n28', 'd49']\n"
     ]
    }
   ],
   "source": [
    "categories=train_diag['cat'].value_counts()[:10]\n",
    "top_categorias = categories.index.to_list()\n",
    "print(top_categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25e458c1-01ec-4c48-8c3e-45f37e4553c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos sólo las etiquetas de este subconjunto\n",
    "train_diag = train_diag[np.isin(train_diag['cat'], top_categorias)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1befd52-7347-4e6d-8760-3a08b5fd8b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 562 entries, S0004-06142005000700014-1 to S2340-98942015000100005-1\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   texto    562 non-null    object\n",
      " 1   codigos  562 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#cargamos los dos conjuntos de train\n",
    "path = 'data/train/text_files/'\n",
    "\n",
    "corpus = []\n",
    "for f in [f for f in os.listdir(path) if f.endswith('.txt')]:\n",
    "    with open(os.path.join(path, f), encoding=\"utf8\") as text:\n",
    "        texto = text.read()\n",
    "    #buscamos códigos\n",
    "    file = f[:-4]\n",
    "    codigos = train_diag.query('archivo==@file')['cat'].to_list()\n",
    "    codigos = list(set(codigos))\n",
    "    if codigos:\n",
    "        corpus.append({\n",
    "            'archivo': file,\n",
    "            'texto': texto,\n",
    "            'codigos': codigos\n",
    "        })\n",
    "    \n",
    "df_train = pd.DataFrame(corpus).set_index('archivo')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf73334-972c-4746-829f-0891641a1b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>codigos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archivo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0365-66912011000600005-2</th>\n",
       "      <td>Varón de 37 años ex-adicto a drogas por vía parenteral y diagnosticado de hepatitis crónica por virus C genotipo 4 con una baja carga viral (75.754 UI/ml). Se instauró tratamiento con IFN pegilado alpha-2b (100µg/semana) y ribavirina (1g/día).\\nA los 2 meses del inicio del tratamiento acudió a la consulta y refirió visión borrosa y «manchas» en el campo visual desde aproximadamente 10 días antes. En la exploración oftalmológica presentó una AV de 0,8 con corrección en ambos ojos y múltiples exudados algodonosos en polo posterior. Se diagnosticó de retinopatía por IFN y se suspendió el tratamiento. En controles sucesivos el cuadro fue mejorando y a los 3 meses presentó una AV de 10/10 en ambos ojos y en el FO únicamente se apreció un exudado algodonoso en reabsorción inferior a fóvea izquierda.\\n\\n</td>\n",
       "      <td>[r60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              texto  \\\n",
       "archivo                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "S0365-66912011000600005-2  Varón de 37 años ex-adicto a drogas por vía parenteral y diagnosticado de hepatitis crónica por virus C genotipo 4 con una baja carga viral (75.754 UI/ml). Se instauró tratamiento con IFN pegilado alpha-2b (100µg/semana) y ribavirina (1g/día).\\nA los 2 meses del inicio del tratamiento acudió a la consulta y refirió visión borrosa y «manchas» en el campo visual desde aproximadamente 10 días antes. En la exploración oftalmológica presentó una AV de 0,8 con corrección en ambos ojos y múltiples exudados algodonosos en polo posterior. Se diagnosticó de retinopatía por IFN y se suspendió el tratamiento. En controles sucesivos el cuadro fue mejorando y a los 3 meses presentó una AV de 10/10 en ambos ojos y en el FO únicamente se apreció un exudado algodonoso en reabsorción inferior a fóvea izquierda.\\n\\n   \n",
       "\n",
       "                          codigos  \n",
       "archivo                            \n",
       "S0365-66912011000600005-2   [r60]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc77de8-8256-4653-9de0-690dacc58095",
   "metadata": {},
   "source": [
    "### Conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d6ea92-47fd-462a-9067-33fdfdfd31a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192 entries, 0 to 191\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   archivo  192 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#los códigos están en un TSV con un código por línea\n",
    "test_diag = pd.read_csv(\"data/test/test.tsv\", sep = \"\\t\", header = None, names = [\"archivo\"])\n",
    "test_diag.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ff5875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 192 entries, S0004-06142005000500011-1 to S2254-28842014000300010-1\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   texto   192 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "path = 'data/test/text_files/'\n",
    "\n",
    "corpus = []\n",
    "for f in [f for f in os.listdir(path) if f.endswith('.txt')]:\n",
    "    file = os.path.splitext(f)[0]\n",
    "    if file in test_diag['archivo'].values:\n",
    "        with open(os.path.join(path, f), encoding=\"utf8\") as text:\n",
    "            texto = text.read()\n",
    "            corpus.append({\n",
    "                'archivo': file,\n",
    "                'texto': texto\n",
    "            })\n",
    "    \n",
    "df_test = pd.DataFrame(corpus).set_index('archivo')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ae159e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archivo</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1887-85712012000400006-1</th>\n",
       "      <td>Mujer de 47 años que consulta en urgencias por un cuadro de 8 horas de evolución con dolor abdominal continuo y difuso, junto con vómitos, primero alimentarios y posteriormente biliosos. La paciente tiene únicamente como antecedentes personales, la realización de dos cesáreas. En urgencias presenta una tensión arterial de 122/85 mmHg, una frecuencia cardíaca de 91 latidos por minuto y una temperatura axilar de 35.9 oC. La exploración abdominal revela una cicatriz de laparotomía media infraumbilical, la presencia de ruidos disminuidos, y dolor a la palpación de manera difusa sin claros signos de irritación peritoneal. No existen hernias inguinales o crurales.\\nEn el análisis de sangre destacan tan solo una glucemia de 122 mg/dL, una leucocitosis de 15.240 uL, junto con neutrofília del 93%, siendo el resto de parámetros normales. La radiografía simple de abdomen es compatible con suboclusión de intestino delgado, y colelitiasis. La TAC de urgencias revela la presencia de asas de intestino delgado dilatadas y sugiere la posibilidad de una torsión intestinal.\\n\\nLos hallazgos en las exploraciones complementarias, junto con el empeoramiento clínico de la paciente durante el periodo de observación y estudio, aumentando los vómitos y el dolor abdominal, así como apareciendo signos de irritación peritoneal en hemiabdomen inferior, hacen que se le proponga una laparoscópia exploradora. La sospecha diagnóstica en ese momento es de oclusión intestinal por bridas, y el tiempo trancurrido desde el ingreso en urgencias, de 16 h.\\nBajo anestesia general se realiza laparoscópia exploradora, identificando en la pelvis de la paciente un asa de intestino delgado estrangulada y necrosada, este asa ocupa la derecha de la figura 3 (color morado/negro), la cual es una fotografía intraoperatoria directa del monitor de la cámara laparoscópica. La parte izquierda de esa imagen se corresponde con el ileon pre-herniario (de color rosa normal), entre ambas zonas de ileon está la trompa de Falopio derecha la cual está adherida a la pared abdominal anterior y bajo ella se extiende el ligamento ancho (no visible en la imagen) y que tendría el orificio a través del cual se produce la herniación, en la figura 4 el autor representa un dibujo esquemático para comprender mejor la anatomía de los hallazgos intraoperatorios. La gran dilatación de asas de intestino delgado, disminuye mucho el espacio de trabajo necesario para manipular el instrumental quirúrgico por laparoscópia. Ese hecho, junto con el riesgo de perforación al manipular el asa necrosada, así como la imposibilidad de identificar con seguridad las estructuras anatómicas, obligan a una reconversión a cirugía abierta. La reconversión se realiza mediante una laparotomía infraumbilical iterativa y se aprecia que la causa de la obstrucción y estrangulación del ileon, es una hernia interna a través de la hoja derecha del ligamento ancho del útero. Se procede a la reducción de la hernia, resección de 25 cm de ileon necrosado y reconstrucción con anastomosis termino-terminal manual. Sobre el orificio herniario se realiza el cierre con sutura continua de seda 0/0. El postoperatorio transcurre con normalidad y la paciente es dada de alta con buen estado clínico a los 11 días del ingreso. El control postoperatorio al mes es correcto.\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       texto\n",
       "archivo                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "S1887-85712012000400006-1  Mujer de 47 años que consulta en urgencias por un cuadro de 8 horas de evolución con dolor abdominal continuo y difuso, junto con vómitos, primero alimentarios y posteriormente biliosos. La paciente tiene únicamente como antecedentes personales, la realización de dos cesáreas. En urgencias presenta una tensión arterial de 122/85 mmHg, una frecuencia cardíaca de 91 latidos por minuto y una temperatura axilar de 35.9 oC. La exploración abdominal revela una cicatriz de laparotomía media infraumbilical, la presencia de ruidos disminuidos, y dolor a la palpación de manera difusa sin claros signos de irritación peritoneal. No existen hernias inguinales o crurales.\\nEn el análisis de sangre destacan tan solo una glucemia de 122 mg/dL, una leucocitosis de 15.240 uL, junto con neutrofília del 93%, siendo el resto de parámetros normales. La radiografía simple de abdomen es compatible con suboclusión de intestino delgado, y colelitiasis. La TAC de urgencias revela la presencia de asas de intestino delgado dilatadas y sugiere la posibilidad de una torsión intestinal.\\n\\nLos hallazgos en las exploraciones complementarias, junto con el empeoramiento clínico de la paciente durante el periodo de observación y estudio, aumentando los vómitos y el dolor abdominal, así como apareciendo signos de irritación peritoneal en hemiabdomen inferior, hacen que se le proponga una laparoscópia exploradora. La sospecha diagnóstica en ese momento es de oclusión intestinal por bridas, y el tiempo trancurrido desde el ingreso en urgencias, de 16 h.\\nBajo anestesia general se realiza laparoscópia exploradora, identificando en la pelvis de la paciente un asa de intestino delgado estrangulada y necrosada, este asa ocupa la derecha de la figura 3 (color morado/negro), la cual es una fotografía intraoperatoria directa del monitor de la cámara laparoscópica. La parte izquierda de esa imagen se corresponde con el ileon pre-herniario (de color rosa normal), entre ambas zonas de ileon está la trompa de Falopio derecha la cual está adherida a la pared abdominal anterior y bajo ella se extiende el ligamento ancho (no visible en la imagen) y que tendría el orificio a través del cual se produce la herniación, en la figura 4 el autor representa un dibujo esquemático para comprender mejor la anatomía de los hallazgos intraoperatorios. La gran dilatación de asas de intestino delgado, disminuye mucho el espacio de trabajo necesario para manipular el instrumental quirúrgico por laparoscópia. Ese hecho, junto con el riesgo de perforación al manipular el asa necrosada, así como la imposibilidad de identificar con seguridad las estructuras anatómicas, obligan a una reconversión a cirugía abierta. La reconversión se realiza mediante una laparotomía infraumbilical iterativa y se aprecia que la causa de la obstrucción y estrangulación del ileon, es una hernia interna a través de la hoja derecha del ligamento ancho del útero. Se procede a la reducción de la hernia, resección de 25 cm de ileon necrosado y reconstrucción con anastomosis termino-terminal manual. Sobre el orificio herniario se realiza el cierre con sutura continua de seda 0/0. El postoperatorio transcurre con normalidad y la paciente es dada de alta con buen estado clínico a los 11 días del ingreso. El control postoperatorio al mes es correcto.\\n\\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b472f280-db6a-438d-8340-f7b19758399b",
   "metadata": {},
   "source": [
    "### Binarizar las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae41be51-448e-433b-b10f-b4236afbaa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# para entrenar un clasificador multi-etiqueta generamos una matriz binaria de las etiquetas\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(df_train['codigos'])\n",
    "\n",
    "#Guardamos las clases utilizadas en el conjunto de train\n",
    "clases = mlb.classes_\n",
    "num_classes = clases.shape\n",
    "print(num_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f59c35",
   "metadata": {},
   "source": [
    "## Procesamiento del lenguaje natural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cdde5f",
   "metadata": {},
   "source": [
    "### BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e63e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download es_core_news_lg\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeb61cb",
   "metadata": {},
   "source": [
    "Obtenemos resultados ligeramente mejores sin realizar un preprocesamiento con la función `normalizeDoc()` previamente a la aplicación del *Bag of Words*. La adición de *n-grams* empeora los resultados de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb424683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_trainText = [normalizeDoc(nlp, doc) for doc in df_train['texto'].values]\n",
    "x_trainText = df_train['texto'].values\n",
    "x_testText = df_test['texto'].values\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x_trainArray = vectorizer.fit_transform(x_trainText)\n",
    "x_testArray = vectorizer.transform(x_testText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b0d0d",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9f9be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train_train, y_train_test = train_test_split(x_trainArray, y_train, test_size = 0.1, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d49be3",
   "metadata": {},
   "source": [
    "### Nuestro mejor modelo: MultiOutput con GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f35a7005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.62      0.73        13\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      0.75      0.86         8\n",
      "           3       0.80      0.57      0.67        14\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      0.93      0.97        15\n",
      "           6       1.00      0.31      0.47        13\n",
      "           7       1.00      0.92      0.96        12\n",
      "           8       0.88      0.88      0.88         8\n",
      "           9       1.00      1.00      1.00        17\n",
      "\n",
      "   micro avg       0.96      0.80      0.87       124\n",
      "   macro avg       0.96      0.80      0.85       124\n",
      "weighted avg       0.96      0.80      0.85       124\n",
      " samples avg       0.92      0.82      0.85       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = GradientBoostingClassifier(loss = 'exponential', n_estimators = 50, max_depth = 5, min_samples_split = 5, random_state = 3)\n",
    "model = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "model.fit(x_train, y_train_train)\n",
    "y_pred = model.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11916ec",
   "metadata": {},
   "source": [
    "### Coseno similitud (*manual*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8476ec88-d3f6-477f-8cc9-d298ce8077b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTag = df_train.index.values\n",
    "\n",
    "x_trainT, x_testT, xTag_train, xTag_test = train_test_split(x_train, xTag, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0689372a-2ed7-45d5-895c-92b4f773c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "x_trainVec = vectorizer.fit_transform(x_trainT)\n",
    "x_trainVecDf = pd.DataFrame(x_trainVec.toarray(), columns = vectorizer.get_feature_names_out(), index = xTag_train)\n",
    "\n",
    "x_testVec = vectorizer.transform(x_testT)\n",
    "x_testVecDf = pd.DataFrame(x_testVec.toarray(), columns = vectorizer.get_feature_names_out(), index = xTag_test)\n",
    "\n",
    "similarity = cosine_similarity(x_testVecDf, x_trainVecDf)\n",
    "similarityDf = pd.DataFrame(similarity, index = x_testVecDf.index, columns = x_trainVecDf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8e24959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>archivoMostSimilar</th>\n",
       "      <th>similarity</th>\n",
       "      <th>codigosPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0210-48062010000100019-4</th>\n",
       "      <td>S0210-48062005000600013-1</td>\n",
       "      <td>0.339525</td>\n",
       "      <td>[n28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1134-80462015000200005-1</th>\n",
       "      <td>S0212-16112010000600024-1</td>\n",
       "      <td>0.269564</td>\n",
       "      <td>[r10, r69, r11, r60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1139-76322009000400007-1</th>\n",
       "      <td>S1137-66272013000300020-1</td>\n",
       "      <td>0.352673</td>\n",
       "      <td>[r10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0376-78922014000100013-1</th>\n",
       "      <td>S0376-78922016000200012-1</td>\n",
       "      <td>0.40826</td>\n",
       "      <td>[r69, d49, i10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1130-01082007001100012-1</th>\n",
       "      <td>S0212-16112010000100017-1</td>\n",
       "      <td>0.221398</td>\n",
       "      <td>[r60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  archivoMostSimilar similarity  \\\n",
       "S0210-48062010000100019-4  S0210-48062005000600013-1   0.339525   \n",
       "S1134-80462015000200005-1  S0212-16112010000600024-1   0.269564   \n",
       "S1139-76322009000400007-1  S1137-66272013000300020-1   0.352673   \n",
       "S0376-78922014000100013-1  S0376-78922016000200012-1    0.40826   \n",
       "S1130-01082007001100012-1  S0212-16112010000100017-1   0.221398   \n",
       "\n",
       "                                    codigosPred  \n",
       "S0210-48062010000100019-4                 [n28]  \n",
       "S1134-80462015000200005-1  [r10, r69, r11, r60]  \n",
       "S1139-76322009000400007-1                 [r10]  \n",
       "S0376-78922014000100013-1       [r69, d49, i10]  \n",
       "S1130-01082007001100012-1                 [r60]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilarDf = findMostSimilar(similarityDf, df_train)\n",
    "\n",
    "mostSimilarDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1d8d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al menos 1 coincidencia: 0.624113475177305\n",
      "Accuracy media: 0.4052178318135765\n"
     ]
    }
   ],
   "source": [
    "mostSimilarDf = checkAccuracy(mostSimilarDf, df_train)\n",
    "print(f\"Al menos 1 coincidencia: {(mostSimilarDf['guess'] != 0).sum() / mostSimilarDf.shape[0]}\")\n",
    "print(f\"Accuracy media: {mostSimilarDf['guess'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651e603",
   "metadata": {},
   "source": [
    "### Otros modelos de clasificación multietiqueta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef20299",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a176f20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       1.00      0.25      0.40        16\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       1.00      0.07      0.13        14\n",
      "           4       1.00      0.25      0.40         8\n",
      "           5       0.75      0.20      0.32        15\n",
      "           6       0.33      0.08      0.12        13\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "   micro avg       0.79      0.09      0.16       124\n",
      "   macro avg       0.41      0.08      0.14       124\n",
      "weighted avg       0.43      0.09      0.14       124\n",
      " samples avg       0.17      0.08      0.11       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_target_classifier = RandomForestClassifier(n_estimators = 10, criterion = 'gini', n_jobs = 4, random_state = 3)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380064f",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "723f59cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.14        13\n",
      "           1       0.80      0.25      0.38        16\n",
      "           2       0.83      0.62      0.71         8\n",
      "           3       1.00      0.29      0.44        14\n",
      "           4       0.20      0.12      0.15         8\n",
      "           5       0.75      0.40      0.52        15\n",
      "           6       0.50      0.23      0.32        13\n",
      "           7       0.83      0.42      0.56        12\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.80      0.24      0.36        17\n",
      "\n",
      "   micro avg       0.70      0.27      0.39       124\n",
      "   macro avg       0.67      0.26      0.36       124\n",
      "weighted avg       0.72      0.27      0.37       124\n",
      " samples avg       0.38      0.25      0.29       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_target_classifier = MLPClassifier(activation = 'logistic', solver = 'adam', max_iter = 1000, random_state = 3)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b54f8",
   "metadata": {},
   "source": [
    "#### K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa4991c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.08      0.13        26\n",
      "           1       0.25      0.06      0.09        35\n",
      "           2       0.33      0.23      0.27        13\n",
      "           3       0.43      0.10      0.17        29\n",
      "           4       0.50      0.04      0.08        23\n",
      "           5       0.40      0.06      0.10        36\n",
      "           6       0.39      0.23      0.29        31\n",
      "           7       0.24      0.20      0.22        25\n",
      "           8       0.67      0.08      0.14        25\n",
      "           9       0.31      0.23      0.26        35\n",
      "\n",
      "   micro avg       0.34      0.13      0.18       278\n",
      "   macro avg       0.40      0.13      0.18       278\n",
      "weighted avg       0.40      0.13      0.17       278\n",
      " samples avg       0.19      0.11      0.13       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_target_classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd551adb",
   "metadata": {},
   "source": [
    "#### MultiOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628531d0",
   "metadata": {},
   "source": [
    "##### Regression Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "091125fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.42        26\n",
      "           1       0.88      0.43      0.58        35\n",
      "           2       0.56      0.69      0.62        13\n",
      "           3       0.87      0.45      0.59        29\n",
      "           4       0.78      0.30      0.44        23\n",
      "           5       0.83      0.42      0.56        36\n",
      "           6       0.53      0.26      0.35        31\n",
      "           7       0.77      0.40      0.53        25\n",
      "           8       0.86      0.24      0.38        25\n",
      "           9       0.88      0.40      0.55        35\n",
      "\n",
      "   micro avg       0.78      0.37      0.51       278\n",
      "   macro avg       0.80      0.39      0.50       278\n",
      "weighted avg       0.81      0.37      0.50       278\n",
      " samples avg       0.50      0.35      0.40       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = LogisticRegression(penalty = 'l2', solver = 'newton-cg', max_iter = 1000, multi_class = 'multinomial')\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "417a9432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.27      0.39        26\n",
      "           1       0.79      0.54      0.64        35\n",
      "           2       0.56      0.69      0.62        13\n",
      "           3       0.78      0.48      0.60        29\n",
      "           4       0.64      0.39      0.49        23\n",
      "           5       0.83      0.53      0.64        36\n",
      "           6       0.53      0.26      0.35        31\n",
      "           7       0.79      0.44      0.56        25\n",
      "           8       0.88      0.28      0.42        25\n",
      "           9       0.89      0.49      0.63        35\n",
      "\n",
      "   micro avg       0.75      0.43      0.55       278\n",
      "   macro avg       0.74      0.44      0.53       278\n",
      "weighted avg       0.75      0.43      0.54       278\n",
      " samples avg       0.55      0.44      0.46       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = PassiveAggressiveClassifier(random_state = 3)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "102daac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.27      0.35        26\n",
      "           1       0.78      0.51      0.62        35\n",
      "           2       0.69      0.69      0.69        13\n",
      "           3       0.88      0.48      0.62        29\n",
      "           4       0.58      0.48      0.52        23\n",
      "           5       0.86      0.50      0.63        36\n",
      "           6       0.41      0.29      0.34        31\n",
      "           7       0.71      0.68      0.69        25\n",
      "           8       0.58      0.28      0.38        25\n",
      "           9       0.76      0.37      0.50        35\n",
      "\n",
      "   micro avg       0.68      0.44      0.54       278\n",
      "   macro avg       0.68      0.46      0.54       278\n",
      "weighted avg       0.69      0.44      0.53       278\n",
      " samples avg       0.53      0.45      0.46       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = SGDClassifier(loss = 'squared_hinge', penalty = 'elasticnet', random_state = 3)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b696cc",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9781407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       1.00      0.31      0.48        16\n",
      "           2       1.00      0.25      0.40         8\n",
      "           3       1.00      0.14      0.25        14\n",
      "           4       0.50      0.12      0.20         8\n",
      "           5       1.00      0.33      0.50        15\n",
      "           6       0.00      0.00      0.00        13\n",
      "           7       0.67      0.17      0.27        12\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.80      0.24      0.36        17\n",
      "\n",
      "   micro avg       0.88      0.17      0.28       124\n",
      "   macro avg       0.60      0.16      0.25       124\n",
      "weighted avg       0.63      0.17      0.26       124\n",
      " samples avg       0.27      0.15      0.18       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = RandomForestClassifier(n_estimators = 10)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5c074",
   "metadata": {},
   "source": [
    "##### Gradient Boosting: Grid Search (mejor modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59e6add7-769c-40b6-931b-1fca0721a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters: {'estimator__max_depth': 5, 'estimator__min_samples_split': 5, 'estimator__n_estimators': 50}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.38      0.49        26\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       0.69      0.69      0.69        13\n",
      "           3       0.87      0.69      0.77        29\n",
      "           4       1.00      0.87      0.93        23\n",
      "           5       1.00      0.94      0.97        36\n",
      "           6       0.82      0.45      0.58        31\n",
      "           7       1.00      0.92      0.96        25\n",
      "           8       0.96      0.92      0.94        25\n",
      "           9       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       0.93      0.80      0.86       278\n",
      "   macro avg       0.90      0.79      0.83       278\n",
      "weighted avg       0.92      0.80      0.85       278\n",
      " samples avg       0.88      0.80      0.82       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = GradientBoostingClassifier(loss = 'exponential', random_state = 3)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [40, 50, 60],\n",
    "    'estimator__max_depth': [3, 5, 7],\n",
    "    'estimator__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
    "\n",
    "grid_search = GridSearchCV(multi_target_classifier, param_grid, cv = 5, scoring = f1_scorer, n_jobs = 4, verbose = 1)\n",
    "grid_search.fit(x_train, y_train_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_estimator = grid_search.best_estimator_\n",
    "best_estimator.fit(x_train, y_train_train)\n",
    "\n",
    "y_pred = best_estimator.predict(x_test)\n",
    "\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9846b1",
   "metadata": {},
   "source": [
    "Intentamos mejorar el modelo añadiendo un `AdaBoostClassifier` para mejorar el *fitting* del estimador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a4bdeabe-13e4-48f6-bc3c-0538b3394303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.46      0.57        26\n",
      "           1       1.00      0.83      0.91        35\n",
      "           2       0.56      0.69      0.62        13\n",
      "           3       0.86      0.66      0.75        29\n",
      "           4       1.00      0.87      0.93        23\n",
      "           5       1.00      0.94      0.97        36\n",
      "           6       0.88      0.45      0.60        31\n",
      "           7       1.00      0.92      0.96        25\n",
      "           8       0.96      0.92      0.94        25\n",
      "           9       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       0.93      0.78      0.85       278\n",
      "   macro avg       0.90      0.77      0.82       278\n",
      "weighted avg       0.92      0.78      0.84       278\n",
      " samples avg       0.84      0.78      0.79       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator = GradientBoostingClassifier(loss = 'exponential', criterion = 'friedman_mse', n_estimators = 50, max_depth = 5, min_samples_split = 5, random_state = 3)\n",
    "base_classifier = AdaBoostClassifier(estimator = estimator, n_estimators = 100, random_state = 3)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838794ad",
   "metadata": {},
   "source": [
    "##### Light Gradient-Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e693b9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.54      0.60        26\n",
      "           1       1.00      0.74      0.85        35\n",
      "           2       0.77      0.77      0.77        13\n",
      "           3       0.81      0.76      0.79        29\n",
      "           4       1.00      0.87      0.93        23\n",
      "           5       1.00      0.89      0.94        36\n",
      "           6       0.56      0.48      0.52        31\n",
      "           7       1.00      0.84      0.91        25\n",
      "           8       0.96      0.92      0.94        25\n",
      "           9       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       0.89      0.78      0.83       278\n",
      "   macro avg       0.88      0.78      0.82       278\n",
      "weighted avg       0.89      0.78      0.83       278\n",
      " samples avg       0.82      0.77      0.77       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = lgb.LGBMClassifier(boosting_type = 'dart', n_estimators = 50, objective = 'binary', random_state = 3)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train.astype(np.float32), y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test.astype(np.float32))\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c7119e-b68d-447f-ae89-ef18c223ebf8",
   "metadata": {},
   "source": [
    "## Guardar predicciones de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6167ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_testArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89cd23",
   "metadata": {},
   "source": [
    "### Etiquetado de textos sin etiqueta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe47a92",
   "metadata": {},
   "source": [
    "#### Asignación de la etiqueta más probable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53288e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-labeled texts: [ 84  85  91  92 108 138 139 140 155 168 169 176 189]\n"
     ]
    }
   ],
   "source": [
    "zeroIdx = np.where(np.sum(y_test_pred, axis = 1) == 0)[0]\n",
    "if zeroIdx.size > 0:\n",
    "    print('Non-labeled texts:', zeroIdx)\n",
    "    probs = model.predict_proba(x_testArray)\n",
    "    for idx in zeroIdx:\n",
    "        oneProb = []\n",
    "        for probArray, classes in zip(probs, model.classes_):\n",
    "            p = probArray[idx][classes == 1][0]\n",
    "            oneProb.append(p)\n",
    "        y_test_pred[idx, np.argmax(oneProb)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ff4d4",
   "metadata": {},
   "source": [
    "#### Active-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcaa1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainStack = x_train\n",
    "y_trainStack = y_train_train\n",
    "x_testStack = x_testArray\n",
    "y_predStack = y_test_pred\n",
    "\n",
    "zeroIdx = np.where(np.sum(y_predStack, axis = 1) == 0)[0]\n",
    "nZeros = []\n",
    "while zeroIdx.size > 0:\n",
    "\n",
    "    model.fit(x_trainStack, y_trainStack)\n",
    "    y_predStack = model.predict(x_testStack)\n",
    "\n",
    "    zeroIdx = np.where(np.sum(y_predStack, axis = 1) == 0)[0]\n",
    "    nZeros.append(zeroIdx.size)\n",
    "\n",
    "    print(x_trainStack.shape, x_testStack.shape, nZeros)\n",
    "\n",
    "    if len(nZeros) >= 3 and (nZeros[-1] == nZeros[-2] == nZeros[-3]):\n",
    "        raise Exception('Active Learning could not label any sample in the last 2 iterations. Quitting...')\n",
    "\n",
    "    x_lab = x_testStack[[i for i in range(x_testStack.shape[0]) if i not in zeroIdx]]\n",
    "    x_testStack = x_testStack[zeroIdx]\n",
    "\n",
    "    y_lab = y_predStack[[i for i in range(y_predStack.shape[0]) if i not in zeroIdx]]\n",
    "\n",
    "    x_trainStack = vstack([x_trainStack, x_lab])\n",
    "    y_trainStack = np.vstack([y_trainStack, y_lab])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0775823c",
   "metadata": {},
   "source": [
    "### Escritura en fichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff863c1c-9821-4ad4-a912-1abe400f5c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192 entries, 0 to 191\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   archivo  192 non-null    object\n",
      " 1   d49      192 non-null    int32 \n",
      " 2   i10      192 non-null    int32 \n",
      " 3   n28      192 non-null    int32 \n",
      " 4   r10      192 non-null    int32 \n",
      " 5   r11      192 non-null    int32 \n",
      " 6   r50      192 non-null    int32 \n",
      " 7   r52      192 non-null    int32 \n",
      " 8   r59      192 non-null    int32 \n",
      " 9   r60      192 non-null    int32 \n",
      " 10  r69      192 non-null    int32 \n",
      "dtypes: int32(10), object(1)\n",
      "memory usage: 9.1+ KB\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(y_test_pred, index = df_test.index, columns = clases)\n",
    "results.reset_index(inplace = True)\n",
    "\n",
    "results.to_csv('results/bow-multioutput-gradientboosting.csv', index = False)\n",
    "results.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

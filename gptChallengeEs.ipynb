{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eca6be9-3ab2-4756-80a0-4880568d1cd7",
   "metadata": {},
   "source": [
    "# GPTChallenge: diagn√≥stico a partir de HCE\n",
    "\n",
    "**Grupo 2: GPTSovereigns** üë®‚Äçüíª\n",
    "\n",
    "Integrantes: \n",
    "- Mart√≠nez Leal, Jes√∫s\n",
    "- Ortega Mediavilla, Samuel\n",
    "- Vicente Mart√≠nez, Pablo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff556ab",
   "metadata": {},
   "source": [
    "**OBJETIVO**. Clasificar texto procedente de historias cl√≠nicas electr√≥nicas en c√≥digo CIE-10 usando ChatGPT.\n",
    "\n",
    "El CIE-10 (Clasificaci√≥n Internacional de Enfermedades, d√©cima edici√≥n) es un sistema de clasificaci√≥n m√©dica utilizado para codificar y clasificar enfermedades y otros problemas de salud. ASigna c√≥digos alfanum√©ricos a una amplia variedad de enfermedades, trastornos, lesiones, causas externas de morbilidad y otros problemas de salud. Cada c√≥digo est√° compuesto por entre 3 y 7 caracteres, que proporcionan informaci√≥n detallada sobre la condici√≥n m√©dica o el evento en cuesti√≥n.\n",
    "\n",
    "Tendremos un **conjunto de train** con historias cl√≠nicas electr√≥nicas y varias etiquetas CIE-10 asociadas, as√≠ como un **conjunto de test** *no etiquetado*. El resultado de la predicci√≥n solo podr√° ser visto al subirlo a una p√°gina web que nos brindaron los profesores, disponiendo de un m√°ximo de **3 intentos**. Para ello, previamente deberemos guardar las predicciones sobre este conjunto en un **dataframe** que exportaremos a formato `.csv`.\n",
    "\n",
    "Ser√° necesario que demos tambi√©n nuestro historial de chat en ChatGPT (uno por integrante) en lo relacionado con el proyecto, por lo que ser√° necesario dar el enlace directo de este (al final del notebook est√°).\n",
    "\n",
    "Por √∫ltimo, se deber√° escribir un art√≠culo cient√≠fico con las secciones siguientes: 1. Introducci√≥n, 2. Materiales y m√©todos, 3. Resultados, 4. Discusi√≥n y 5. Conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5ba28",
   "metadata": {},
   "source": [
    "Aunque el dataset de **train** tiene casi 1000 c√≥digos, tomaremos solo las historias cl√≠nicas con los **10 c√≥digos m√°s frecuentes**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49d9698",
   "metadata": {},
   "source": [
    "=============================================================================================================================================================================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de358c45-755b-4fad-9d68-72e591de8b4b",
   "metadata": {},
   "source": [
    "Vamos a trabajar con el corpus **CodEsp** (textos de historial cl√≠nico etiquetados con sus c√≥digos CIE-10 Diagn√≥stico). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdaf085",
   "metadata": {},
   "source": [
    "## Carga de librer√≠as y definici√≥n de funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d4da20-1cea-4309-941f-c2440b01801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # used for data manipulation\n",
    "import os, re, spacy # used for text processing, regular expressions, and nlp purposes\n",
    "import numpy as np # used for numerical operations\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer # used for encoding labels\n",
    "from sklearn.feature_extraction.text import CountVectorizer # used for text vectorization\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier # used for classification\n",
    "from sklearn.neighbors import KNeighborsClassifier # used for classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier # used for classification, ensemble methods\n",
    "from sklearn.multioutput import MultiOutputClassifier # used for multi-label classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # used for splitting data, hyperparameter tuning\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score # used for evaluation\n",
    "from sklearn.metrics.pairwise import cosine_similarity # used for similarity calculation\n",
    "\n",
    "import lightgbm as lgb # used for classification\n",
    "from scipy.sparse import vstack # used for stacking sparse matrices\n",
    "\n",
    "pd.options.display.max_colwidth = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d476c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3 # semilla uwu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9e5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDoc(nlp, doc, nMinCharacters = 0):\n",
    "    \"\"\"\n",
    "    Normaliza un texto eliminando palabras por debajo del m√≠nimo de caracteres, stop words y n√∫meros.\n",
    "    Para ello, tokeniza empleando un modelo de Spacy.\n",
    "    \"\"\"\n",
    "    # Separar en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # Filtrar tokens\n",
    "    filtered_tokens = [t.lower_ for t in tokens if (len(t.text) >= nMinCharacters) and not t.is_punct and not re.match('[0-9]+', t.text)] # Filtrar palabras por longitud y quitar n√∫meros y signos de puntuaci√≥n\n",
    "    # Recombinamos los tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return doc\n",
    "\n",
    "def findMostSimilar(similarityDf: pd.DataFrame, data: pd.DataFrame, nMostSimilars: int = 1):\n",
    "    \"\"\"\n",
    "    Encuentra la etiqueta de los documentos m√°s similares.\n",
    "    \"\"\"\n",
    "    # Crear df de resultados\n",
    "    results = pd.DataFrame(index = similarityDf.index, columns = ['archivoMostSimilar', 'similarity', 'codigosPred'])\n",
    "\n",
    "    for index, row in similarityDf.iterrows():\n",
    "        \n",
    "        # Buscar la m√°xima similitud\n",
    "        mostSimilar = row.nlargest(nMostSimilars)\n",
    "        \n",
    "        results.loc[index, 'archivoMostSimilar'] = mostSimilar.index.values\n",
    "        if nMostSimilars == 1:\n",
    "            results.loc[index, 'similarity'] = mostSimilar.values[0]\n",
    "        else:\n",
    "            results.loc[index, 'similarity'] = row[mostSimilar.index]\n",
    "\n",
    "    # Coger las etiquetas\n",
    "    if nMostSimilars == 1:\n",
    "        results['codigosPred'] = data.loc[np.squeeze(np.vstack(results['archivoMostSimilar'].values)), 'codigos'].values\n",
    "    else:\n",
    "        pass\n",
    "    return results\n",
    "\n",
    "def checkAccuracy(pred: pd.DataFrame, data: pd.DataFrame):\n",
    "    pred['codigos'] = data.loc[pred.index, 'codigos']\n",
    "\n",
    "    pred['guess'] = pred.apply(\n",
    "        lambda row: len(set(row['codigosPred']).intersection(row['codigos'])) / len(row['codigosPred']),\n",
    "        axis = 1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e8803",
   "metadata": {},
   "source": [
    "## Lectura y preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c8c08",
   "metadata": {},
   "source": [
    "### Conjunto de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566a8909-46d3-4ccd-8a67-96d819f60e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8316 entries, 0 to 8315\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   archivo  8316 non-null   object\n",
      " 1   codigo   8316 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 130.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#los c√≥digos est√°n en un TSV con un c√≥digo por l√≠nea\n",
    "train_diag = pd.read_csv(\"data/train/train.tsv\", sep=\"\\t\", header=None, names=[\"archivo\", \"codigo\"])\n",
    "train_diag.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cbd33aa-1d54-419f-a1f1-728bb03b79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "r52    163\n",
      "r10    163\n",
      "r59    160\n",
      "r69    150\n",
      "r50    144\n",
      "      ... \n",
      "c31      1\n",
      "d62      1\n",
      "s53      1\n",
      "s34      1\n",
      "n81      1\n",
      "Name: count, Length: 918, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "918"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cogemos la categor√≠a superior de cada c√≥digo y las agrupamos\n",
    "train_diag['cat'] = train_diag['codigo'].str.extract(r'(\\w\\d\\d)')\n",
    "print(train_diag['cat'].value_counts())\n",
    "train_diag['cat'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eaf143a-b460-410e-8af2-a268181153d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r52', 'r10', 'r59', 'r69', 'r50', 'r60', 'i10', 'r11', 'n28', 'd49']\n"
     ]
    }
   ],
   "source": [
    "categories=train_diag['cat'].value_counts()[:10] # cogemos las 10 categor√≠as m√°s comunes\n",
    "top_categorias = categories.index.to_list()\n",
    "print(top_categorias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e458c1-01ec-4c48-8c3e-45f37e4553c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos s√≥lo las etiquetas de este subconjunto\n",
    "train_diag = train_diag[np.isin(train_diag['cat'], top_categorias)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1befd52-7347-4e6d-8760-3a08b5fd8b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 562 entries, S0004-06142005000700014-1 to S2340-98942015000100005-1\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   texto    562 non-null    object\n",
      " 1   codigos  562 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#cargamos los dos conjuntos de train\n",
    "path = 'data/train/text_files/'\n",
    "\n",
    "corpus = []\n",
    "for f in [f for f in os.listdir(path) if f.endswith('.txt')]:\n",
    "    with open(os.path.join(path, f), encoding=\"utf8\") as text:\n",
    "        texto = text.read()\n",
    "    #buscamos c√≥digos\n",
    "    file = f[:-4]\n",
    "    codigos = train_diag.query('archivo==@file')['cat'].to_list()\n",
    "    codigos = list(set(codigos))\n",
    "    if codigos:\n",
    "        corpus.append({\n",
    "            'archivo': file,\n",
    "            'texto': texto,\n",
    "            'codigos': codigos\n",
    "        })\n",
    "    \n",
    "df_train = pd.DataFrame(corpus).set_index('archivo')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf73334-972c-4746-829f-0891641a1b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>codigos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archivo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1130-01082008001000010-1</th>\n",
       "      <td>Var√≥n de 43 a√±os originario de Marruecos, que ingres√≥ en nuestro servicio por cuadro de 4 d√≠as de evoluci√≥n de ictericia mucocut√°nea indolora, coluria y prurito generalizado. Como √∫nicos antecedentes de inter√©s destacaban una tuberculosis tratada, hipercolesterolemia en tratamiento diet√©tico y tabaquismo leve. La anal√≠tica mostr√≥ los siguientes datos: bilirrubina 19,44 mg/dl, GOT 110 UI/ml, GPT 371 UI/ml, GGT 632 UI/ml, FA 787 UI/ml, LDH 394 UI/ml. Amilasa y lipasa fueron normales en todo momento. Destacaba tambi√©n una hipergammaglobulinemia (gammaglobulina 1,56%), con IgG 1840 UI/ml (751-1.560 UI/ml). El marcador CA 19-9 era de 82 UI/ml. Los autoanticuerpos (ANA, AMA, AMA-2, ANCA, LKM1, SMA, SLA y F-actina) y serolog√≠as para virus y bacterias (VHA, VHB, VHC, HIV, CMV, VEB, VVZ, VHS, virus de la parotidis, parvovirus B19, Brucella, Borrelia, Coxiella, Leishmania, Rickettsias y Toxoplasma) fueron negativos. La ecograf√≠a abdominal mostr√≥ dilataci√≥n de la v√≠a biliar intra- y extrahep√°tica y la ecoendoscopia (USE) un p√°ncreas aumentado de tama√±o con una lesi√≥n focal de 3 cm a nivel de cabeza y leve dilataci√≥n posterior del conducto pancre√°tico. La TAC toracoabdominal objetiv√≥ adem√°s un p√°ncreas aumentado globalmente de tama√±o, hipodenso, con un halo peripancre√°tico hipodenso, con borde liso, sin afectaci√≥n de la grasa peripancre√°tica, y, a nivel retroperitoneal, en localizaci√≥n peria√≥rtica con extensi√≥n a territorio iliaco bilateral, un tejido denso rodeando dichas estructuras vasculares como un estuche, siendo todo ello compatible con pancreatitis autoinmune con fibrosis retroperitoneal. Ante la persistencia de prurito y la colestasis manifiesta se realiz√≥ un drenaje biliar percut√°neo mostrando la colangiograf√≠a una lesi√≥n estenosante en col√©doco distal sugerente de neoplasia pancre√°tica. Ante dicha posibilidad como primer diagn√≥stico diferencial, se realiz√≥ una punci√≥n-aspiraci√≥n con aguja fina guiada por USE con citolog√≠a negativa para c√©lulas malignas y tinci√≥n Zielh negativa. Dada la ausencia de confirmaci√≥n de neoplasia, y con la sospecha de pancreatitis autoinmune, se realiz√≥ una colangiopancreatograf√≠a retr√≥grada endosc√≥pica (CPRE) observando dilataci√≥n de la v√≠a biliar principal con una estenosis regular en su porci√≥n distal, de unos 3-4 cm, de aspecto benigno, sobre la que se coloc√≥ una endopr√≥tesis pl√°stica. Se inici√≥ tratamiento con corticoides (metilprednisolona a dosis de 32 mg/d√≠a) y se retir√≥ el drenaje percut√°neo. Con el diagn√≥stico de probable PAI el paciente fue dado de alta y seguido de forma ambulatoria comprobando normalizaci√≥n de todos los par√°metros anal√≠ticos y la resoluci√≥n en la TAC abdominal de control, al mes y a los 4 meses, de las lesiones descritas inicialmente, con normalizaci√≥n del tama√±o y aspecto pancre√°tico y desaparici√≥n de la fibrosis retroperitoneal. La dosis de corticoides fue disminuy√©ndose progresivamente hasta su retirada completa al 4¬∫ mes, retir√°ndose tambi√©n la endopr√≥tesis biliar. Hasta la fecha actual, tras 24 meses de seguimiento, el paciente ha permanecido asintom√°tico sin presentar recurrencia de la pancreatitis autoinmune ni de la fibrosis retroperitoneal.\\n\\n</td>\n",
       "      <td>[d49]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   texto  \\\n",
       "archivo                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "S1130-01082008001000010-1  Var√≥n de 43 a√±os originario de Marruecos, que ingres√≥ en nuestro servicio por cuadro de 4 d√≠as de evoluci√≥n de ictericia mucocut√°nea indolora, coluria y prurito generalizado. Como √∫nicos antecedentes de inter√©s destacaban una tuberculosis tratada, hipercolesterolemia en tratamiento diet√©tico y tabaquismo leve. La anal√≠tica mostr√≥ los siguientes datos: bilirrubina 19,44 mg/dl, GOT 110 UI/ml, GPT 371 UI/ml, GGT 632 UI/ml, FA 787 UI/ml, LDH 394 UI/ml. Amilasa y lipasa fueron normales en todo momento. Destacaba tambi√©n una hipergammaglobulinemia (gammaglobulina 1,56%), con IgG 1840 UI/ml (751-1.560 UI/ml). El marcador CA 19-9 era de 82 UI/ml. Los autoanticuerpos (ANA, AMA, AMA-2, ANCA, LKM1, SMA, SLA y F-actina) y serolog√≠as para virus y bacterias (VHA, VHB, VHC, HIV, CMV, VEB, VVZ, VHS, virus de la parotidis, parvovirus B19, Brucella, Borrelia, Coxiella, Leishmania, Rickettsias y Toxoplasma) fueron negativos. La ecograf√≠a abdominal mostr√≥ dilataci√≥n de la v√≠a biliar intra- y extrahep√°tica y la ecoendoscopia (USE) un p√°ncreas aumentado de tama√±o con una lesi√≥n focal de 3 cm a nivel de cabeza y leve dilataci√≥n posterior del conducto pancre√°tico. La TAC toracoabdominal objetiv√≥ adem√°s un p√°ncreas aumentado globalmente de tama√±o, hipodenso, con un halo peripancre√°tico hipodenso, con borde liso, sin afectaci√≥n de la grasa peripancre√°tica, y, a nivel retroperitoneal, en localizaci√≥n peria√≥rtica con extensi√≥n a territorio iliaco bilateral, un tejido denso rodeando dichas estructuras vasculares como un estuche, siendo todo ello compatible con pancreatitis autoinmune con fibrosis retroperitoneal. Ante la persistencia de prurito y la colestasis manifiesta se realiz√≥ un drenaje biliar percut√°neo mostrando la colangiograf√≠a una lesi√≥n estenosante en col√©doco distal sugerente de neoplasia pancre√°tica. Ante dicha posibilidad como primer diagn√≥stico diferencial, se realiz√≥ una punci√≥n-aspiraci√≥n con aguja fina guiada por USE con citolog√≠a negativa para c√©lulas malignas y tinci√≥n Zielh negativa. Dada la ausencia de confirmaci√≥n de neoplasia, y con la sospecha de pancreatitis autoinmune, se realiz√≥ una colangiopancreatograf√≠a retr√≥grada endosc√≥pica (CPRE) observando dilataci√≥n de la v√≠a biliar principal con una estenosis regular en su porci√≥n distal, de unos 3-4 cm, de aspecto benigno, sobre la que se coloc√≥ una endopr√≥tesis pl√°stica. Se inici√≥ tratamiento con corticoides (metilprednisolona a dosis de 32 mg/d√≠a) y se retir√≥ el drenaje percut√°neo. Con el diagn√≥stico de probable PAI el paciente fue dado de alta y seguido de forma ambulatoria comprobando normalizaci√≥n de todos los par√°metros anal√≠ticos y la resoluci√≥n en la TAC abdominal de control, al mes y a los 4 meses, de las lesiones descritas inicialmente, con normalizaci√≥n del tama√±o y aspecto pancre√°tico y desaparici√≥n de la fibrosis retroperitoneal. La dosis de corticoides fue disminuy√©ndose progresivamente hasta su retirada completa al 4¬∫ mes, retir√°ndose tambi√©n la endopr√≥tesis biliar. Hasta la fecha actual, tras 24 meses de seguimiento, el paciente ha permanecido asintom√°tico sin presentar recurrencia de la pancreatitis autoinmune ni de la fibrosis retroperitoneal.\\n\\n   \n",
       "\n",
       "                          codigos  \n",
       "archivo                            \n",
       "S1130-01082008001000010-1   [d49]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc77de8-8256-4653-9de0-690dacc58095",
   "metadata": {},
   "source": [
    "### Conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6a6ad4",
   "metadata": {},
   "source": [
    "Repetimos algo similar, pero ahora no tenemos las etiquetas disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4d6ea92-47fd-462a-9067-33fdfdfd31a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192 entries, 0 to 191\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   archivo  192 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#los c√≥digos est√°n en un TSV con un c√≥digo por l√≠nea\n",
    "test_diag = pd.read_csv(\"data/test/test.tsv\", sep = \"\\t\", header = None, names = [\"archivo\"])\n",
    "test_diag.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80ff5875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 192 entries, S0004-06142005000500011-1 to S2254-28842014000300010-1\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   texto   192 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "path = 'data/test/text_files/'\n",
    "\n",
    "corpus = []\n",
    "for f in [f for f in os.listdir(path) if f.endswith('.txt')]:\n",
    "    file = os.path.splitext(f)[0]\n",
    "    if file in test_diag['archivo'].values:\n",
    "        with open(os.path.join(path, f), encoding=\"utf8\") as text:\n",
    "            texto = text.read()\n",
    "            corpus.append({\n",
    "                'archivo': file,\n",
    "                'texto': texto\n",
    "            })\n",
    "    \n",
    "df_test = pd.DataFrame(corpus).set_index('archivo')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ae159e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archivo</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0004-06142007000900012-1</th>\n",
       "      <td>Mujer de 67 a√±os de edad con antecedentes personales de apendicectom√≠a, hernia discal y de hiato, fractura de tibia y peron√©, as√≠ como c√≥lico nefr√≠tico derecho que acude a consulta de urolog√≠a para revisi√≥n. En el estudio ecogr√°fico, se observa una neoformaci√≥n s√≥lida en ri√±√≥n derecho de 5 cm.; se realiza TAC en el que se describe una masa a nivel cortical de ri√±√≥n derecho, de aproximadamente 5 cm, de bordes externos lobulados, que no parece afectar al espacio perirrenal, no observ√°ndose adenopat√≠as, ni dilataci√≥n de v√≠a renal excretora. Con el diagn√≥stico de probable hipernefroma se realiza nefrectom√≠a radical derecha mediante laparoscopia.\\n\\nEn el estudio macrosc√≥pico se describe una neoformaci√≥n cortical de 5 cm de di√°metro m√°ximo, bien delimitada, pero no encapsulada, que deforma la superficie cortical sin atravesarla, con una superficie de corte de coloraci√≥n amarillenta con √°reas de aspecto hemorr√°gicas y √°reas qu√≠sticas.\\nEn el estudio microsc√≥pico la neoformaci√≥n est√° constituida por estructuras acinares tapizadas por peque√±as c√©lulas cuboidales uniformes, con escaso citoplasma y n√∫cleos con cromatina uniforme, inmersas en un estroma ligeramente celular. Se realiz√≥ estudio inmunohistoqu√≠mico para determinaci√≥n de vimentina, citoqueratina 7, citoqueratina de amplio espectro, CD34, cromogranina y EMA (Master Diagnostic. Granada. Espa√±a), observ√°ndose expresi√≥n generalizada de vimentina, focal de citoqueraina 7 y EMA en las c√©lulas epiteliales, y CD34 en el componente estromal.\\n\\nLa paciente cursa tras la intervenci√≥n sin incidentes destacables y se encuentra asintom√°tica a los 24 meses de la intervenci√≥n.\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  texto\n",
       "archivo                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "S0004-06142007000900012-1  Mujer de 67 a√±os de edad con antecedentes personales de apendicectom√≠a, hernia discal y de hiato, fractura de tibia y peron√©, as√≠ como c√≥lico nefr√≠tico derecho que acude a consulta de urolog√≠a para revisi√≥n. En el estudio ecogr√°fico, se observa una neoformaci√≥n s√≥lida en ri√±√≥n derecho de 5 cm.; se realiza TAC en el que se describe una masa a nivel cortical de ri√±√≥n derecho, de aproximadamente 5 cm, de bordes externos lobulados, que no parece afectar al espacio perirrenal, no observ√°ndose adenopat√≠as, ni dilataci√≥n de v√≠a renal excretora. Con el diagn√≥stico de probable hipernefroma se realiza nefrectom√≠a radical derecha mediante laparoscopia.\\n\\nEn el estudio macrosc√≥pico se describe una neoformaci√≥n cortical de 5 cm de di√°metro m√°ximo, bien delimitada, pero no encapsulada, que deforma la superficie cortical sin atravesarla, con una superficie de corte de coloraci√≥n amarillenta con √°reas de aspecto hemorr√°gicas y √°reas qu√≠sticas.\\nEn el estudio microsc√≥pico la neoformaci√≥n est√° constituida por estructuras acinares tapizadas por peque√±as c√©lulas cuboidales uniformes, con escaso citoplasma y n√∫cleos con cromatina uniforme, inmersas en un estroma ligeramente celular. Se realiz√≥ estudio inmunohistoqu√≠mico para determinaci√≥n de vimentina, citoqueratina 7, citoqueratina de amplio espectro, CD34, cromogranina y EMA (Master Diagnostic. Granada. Espa√±a), observ√°ndose expresi√≥n generalizada de vimentina, focal de citoqueraina 7 y EMA en las c√©lulas epiteliales, y CD34 en el componente estromal.\\n\\nLa paciente cursa tras la intervenci√≥n sin incidentes destacables y se encuentra asintom√°tica a los 24 meses de la intervenci√≥n.\\n\\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b472f280-db6a-438d-8340-f7b19758399b",
   "metadata": {},
   "source": [
    "### Binarizar las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae41be51-448e-433b-b10f-b4236afbaa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# para entrenar un clasificador multi-etiqueta generamos una matriz binaria de las etiquetas\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(df_train['codigos'])\n",
    "\n",
    "#Guardamos las clases utilizadas en el conjunto de train\n",
    "clases = mlb.classes_\n",
    "num_classes = clases.shape\n",
    "print(num_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f59c35",
   "metadata": {},
   "source": [
    "## Procesamiento del lenguaje natural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de409c67",
   "metadata": {},
   "source": [
    "En esta secci√≥n se llevar√° a cabo el procesamiento de los textos provenientes de las historias cl√≠nicas usando t√©cnicas de NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f1e21",
   "metadata": {},
   "source": [
    "Con la librer√≠a de spacy cargamos el modelo `es_core_news_lg` de Spacy. El sufijo *lg* indica que es un modelo de tama√±o grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53ed5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download es_core_news_lg\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cdde5f",
   "metadata": {},
   "source": [
    "### BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049e3c4d",
   "metadata": {},
   "source": [
    "El enfoque Bag of Words (BoW) es una t√©cnica simple pero efectiva utilizada en el procesamiento de lenguaje natural para representar documentos de texto como vectores num√©ricos. La idea detr√°s de BoW es tratar cada documento como un \"saco\" de palabras, sin tener en cuenta el orden en que aparecen las palabras en el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeb61cb",
   "metadata": {},
   "source": [
    "Obtenemos resultados ligeramente mejores sin realizar un preprocesamiento con la funci√≥n `normalizeDoc()` previamente a la aplicaci√≥n del *Bag of Words*. La adici√≥n de *n-grams* empeora los resultados de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb424683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_trainText = [normalizeDoc(nlp, doc) for doc in df_train['texto'].values]\n",
    "x_trainText = df_train['texto'].values\n",
    "x_testText = df_test['texto'].values\n",
    "\n",
    "vectorizer = CountVectorizer() # para el bag of words, de sklearn\n",
    "x_trainArray = vectorizer.fit_transform(x_trainText) # matriz tipo sparse\n",
    "x_testArray = vectorizer.transform(x_testText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b7b747",
   "metadata": {},
   "source": [
    "Las matrices sparse `x_trainArray` y `x_testArray` contienen los recuentos de palabras del BoW para train y test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b0d0d",
   "metadata": {},
   "source": [
    "## Modelos (usando `es_core_news_lg`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e74155",
   "metadata": {},
   "source": [
    "Empezamos dividiendo nuestro conjunto de training en dos subconjuntos, que nos permitan distinguir entre lo que ser√≠a el conjunto de training y el de testing. Estrictamente, es un conjunto de validaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9f9be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train_train, y_train_test = train_test_split(x_trainArray, y_train, test_size = 0.1, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d49be3",
   "metadata": {},
   "source": [
    "### Nuestro mejor modelo: MultiOutput con GradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc7f992",
   "metadata": {},
   "source": [
    "Se aplica un modelo de clasificaci√≥n conocido como **Gradient Boosting Classifier**, el cual es una t√©cnica de ensemble learning que combina m√∫ltiples modelos de √°rboles de decisi√≥n d√©biles para construir un modelo m√°s robusto y preciso. Este modelo se caracteriza por ajustar secuencialmente nuevos √°rboles de decisi√≥n a los residuos del modelo anterior, lo que permite mejorar gradualmente la predicci√≥n. En este caso particular, se utilizar√° una variante del Gradient Boosting Classifier con una funci√≥n de p√©rdida exponencial y se configurar√°n varios hiperpar√°metros, como el n√∫mero de estimadores, la profundidad m√°xima del √°rbol y el n√∫mero m√≠nimo de muestras requeridas para dividir un nodo.\n",
    "\n",
    "Con el **MultiOutputClassifier** tendremos un clasificador por target. Esta es una estrategia simple para extender clasificadores que de manera nativa no soportan una clasificaci√≥n multi-output.\n",
    "\n",
    " Una vez que el modelo est√© entrenado, se evaluar√° su rendimiento utilizando m√©tricas como la precisi√≥n, el recall y el puntaje F1 a trav√©s de un informe de clasificaci√≥n.\n",
    "\n",
    "Informaci√≥n `GradientBoostingClassifier()`: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html.\n",
    "\n",
    "Informaci√≥n `MultiOutputClassifier()`: https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f2927cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 17317)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f35a7005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.62      0.73        13\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      0.75      0.86         8\n",
      "           3       0.80      0.57      0.67        14\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      0.93      0.97        15\n",
      "           6       1.00      0.31      0.47        13\n",
      "           7       1.00      0.92      0.96        12\n",
      "           8       0.88      0.88      0.88         8\n",
      "           9       1.00      1.00      1.00        17\n",
      "\n",
      "   micro avg       0.96      0.80      0.87       124\n",
      "   macro avg       0.96      0.80      0.85       124\n",
      "weighted avg       0.96      0.80      0.85       124\n",
      " samples avg       0.92      0.82      0.85       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = GradientBoostingClassifier(loss = 'exponential', n_estimators = 50, max_depth = 5, min_samples_split = 5, random_state = seed)\n",
    "model = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "model.fit(x_train, y_train_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0) # zero_division = 0 para evitar warnings\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6c3f68",
   "metadata": {},
   "source": [
    "Vemos que obtenemos un f1-score de 0.85 en la versi√≥n `weighted` para el conjunto de validaci√≥n que hab√≠amos previamente establecido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11916ec",
   "metadata": {},
   "source": [
    "### Coseno similitud (*manual*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaff3c0",
   "metadata": {},
   "source": [
    "En esta subsecci√≥n se usa una t√©cnica de similitud coseno manual para encontrar los documentos m√°s similares dentro del conjunto de entrenamiento en relaci√≥n con los documentos del conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c275e5",
   "metadata": {},
   "source": [
    "Hacemos primeramente una divisi√≥n para los textos tambi√©n, al igual que hicimos anteriormente con las matrices sparse (mantenemos mismo random_state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8476ec88-d3f6-477f-8cc9-d298ce8077b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTag = df_train.index.values \n",
    "\n",
    "x_trainT, x_testT, xTag_train, xTag_test = train_test_split(x_trainText, xTag, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0689372a-2ed7-45d5-895c-92b4f773c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "x_trainVec = vectorizer.fit_transform(x_trainT)\n",
    "x_trainVecDf = pd.DataFrame(x_trainVec.toarray(), columns = vectorizer.get_feature_names_out(), index = xTag_train)\n",
    "\n",
    "x_testVec = vectorizer.transform(x_testT)\n",
    "x_testVecDf = pd.DataFrame(x_testVec.toarray(), columns = vectorizer.get_feature_names_out(), index = xTag_test)\n",
    "\n",
    "similarity = cosine_similarity(x_testVecDf, x_trainVecDf)\n",
    "similarityDf = pd.DataFrame(similarity, index = x_testVecDf.index, columns = x_trainVecDf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8e24959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>archivoMostSimilar</th>\n",
       "      <th>similarity</th>\n",
       "      <th>codigosPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0210-48062010000100019-4</th>\n",
       "      <td>S0210-48062009000900017-1</td>\n",
       "      <td>0.723986</td>\n",
       "      <td>[d49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1134-80462015000200005-1</th>\n",
       "      <td>S0376-78922016000200012-1</td>\n",
       "      <td>0.877009</td>\n",
       "      <td>[r69, d49, i10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1139-76322009000400007-1</th>\n",
       "      <td>S1698-69462006000400005-1</td>\n",
       "      <td>0.829529</td>\n",
       "      <td>[n28, d49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0376-78922014000100013-1</th>\n",
       "      <td>S0376-78922016000200012-1</td>\n",
       "      <td>0.878946</td>\n",
       "      <td>[r69, d49, i10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1130-01082007001100012-1</th>\n",
       "      <td>S0212-16112010000100017-1</td>\n",
       "      <td>0.690295</td>\n",
       "      <td>[r60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  archivoMostSimilar similarity  \\\n",
       "S0210-48062010000100019-4  S0210-48062009000900017-1   0.723986   \n",
       "S1134-80462015000200005-1  S0376-78922016000200012-1   0.877009   \n",
       "S1139-76322009000400007-1  S1698-69462006000400005-1   0.829529   \n",
       "S0376-78922014000100013-1  S0376-78922016000200012-1   0.878946   \n",
       "S1130-01082007001100012-1  S0212-16112010000100017-1   0.690295   \n",
       "\n",
       "                               codigosPred  \n",
       "S0210-48062010000100019-4            [d49]  \n",
       "S1134-80462015000200005-1  [r69, d49, i10]  \n",
       "S1139-76322009000400007-1       [n28, d49]  \n",
       "S0376-78922014000100013-1  [r69, d49, i10]  \n",
       "S1130-01082007001100012-1            [r60]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilarDf = findMostSimilar(similarityDf, df_train)\n",
    "\n",
    "mostSimilarDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1d8d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al menos 1 coincidencia: 0.4397163120567376\n",
      "Accuracy media: 0.2504728132387707\n"
     ]
    }
   ],
   "source": [
    "mostSimilarDf = checkAccuracy(mostSimilarDf, df_train)\n",
    "print(f\"Al menos 1 coincidencia: {(mostSimilarDf['guess'] != 0).sum() / mostSimilarDf.shape[0]}\")\n",
    "print(f\"Accuracy media: {mostSimilarDf['guess'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651e603",
   "metadata": {},
   "source": [
    "### Otros modelos de clasificaci√≥n multietiqueta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef20299",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da121c0",
   "metadata": {},
   "source": [
    "El modelo de Random Forest es una t√©cnica de aprendizaje autom√°tico que se basa en la construcci√≥n de m√∫ltiples √°rboles de decisi√≥n durante el proceso de entrenamiento y combina sus predicciones para obtener una predicci√≥n final. Cada √°rbol en el bosque se entrena de forma independiente utilizando un subconjunto aleatorio de las caracter√≠sticas y las muestras del conjunto de entrenamiento, lo que fomenta la diversidad entre los √°rboles y ayuda a reducir el sobreajuste.\n",
    "\n",
    "Una de las caracter√≠sticas clave del modelo de Random Forest es su capacidad para manejar problemas de m√∫ltiples salidas o multioutput."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aca665",
   "metadata": {},
   "source": [
    "Hemos comprobado que aumentar el n√∫mero de estimadores, `n_estimators` disminuye dr√°sticamente los resultados. Es por eso que tenemos un n√∫mero bajo. \n",
    "Por otra parte, el criterio `criterion` no parece afectar de manera significativa a los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a176f20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.08      0.12        13\n",
      "           1       0.86      0.38      0.52        16\n",
      "           2       0.50      0.12      0.20         8\n",
      "           3       0.50      0.29      0.36        14\n",
      "           4       0.75      0.38      0.50         8\n",
      "           5       0.50      0.33      0.40        15\n",
      "           6       0.36      0.31      0.33        13\n",
      "           7       0.60      0.25      0.35        12\n",
      "           8       0.50      0.12      0.20         8\n",
      "           9       0.33      0.12      0.17        17\n",
      "\n",
      "   micro avg       0.51      0.24      0.33       124\n",
      "   macro avg       0.52      0.24      0.32       124\n",
      "weighted avg       0.51      0.24      0.32       124\n",
      " samples avg       0.36      0.26      0.28       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_target_classifier = RandomForestClassifier(n_estimators = 3, criterion = 'gini', n_jobs = 4, random_state = seed)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0483d1f",
   "metadata": {},
   "source": [
    "La semilla `random_state` depende enormemente de los resultados que se obtienen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380064f",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0225c0a6",
   "metadata": {},
   "source": [
    "El MLPClassifier, que representa el Perceptr√≥n Multicapa (Multilayer Perceptron) en la biblioteca scikit-learn, es una poderosa herramienta de aprendizaje supervisado utilizada para la clasificaci√≥n. Basado en redes neuronales artificiales, el MLPClassifier es conocido por su capacidad para modelar relaciones complejas entre las caracter√≠sticas de entrada y las etiquetas de salida en conjuntos de datos.\n",
    "\n",
    "Al aprovechar una arquitectura de red neuronal con m√∫ltiples capas de nodos interconectados, el MLPClassifier puede aprender patrones no lineales en los datos.\n",
    "\n",
    "M√°s informaci√≥n: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc9c39",
   "metadata": {},
   "source": [
    "Usamos el optimizador `Adam` ya que generalmente es el que mejores resultados ofrece. Las redes neuronales por construcci√≥n tambi√©n van a admitir f√°cilmente una clasificaci√≥n multi-output. `MLPClassifier` gestiona eso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "723f59cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.14        13\n",
      "           1       0.50      0.06      0.11        16\n",
      "           2       1.00      0.50      0.67         8\n",
      "           3       1.00      0.21      0.35        14\n",
      "           4       0.50      0.12      0.20         8\n",
      "           5       0.80      0.27      0.40        15\n",
      "           6       0.50      0.15      0.24        13\n",
      "           7       1.00      0.33      0.50        12\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       1.00      0.12      0.21        17\n",
      "\n",
      "   micro avg       0.79      0.18      0.29       124\n",
      "   macro avg       0.73      0.19      0.28       124\n",
      "weighted avg       0.76      0.18      0.28       124\n",
      " samples avg       0.30      0.18      0.21       124\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jesus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "multi_target_classifier = MLPClassifier(activation = 'relu', solver = 'adam', max_iter = 1000, random_state = seed)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd551adb",
   "metadata": {},
   "source": [
    "#### MultiOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915b4c7b",
   "metadata": {},
   "source": [
    "Se muestran a continuaci√≥n otros resultados con clasificadores a los que se les a√±ade la funcionalidad que proporciona `MultiOutputClassifier`.\n",
    "\n",
    "Con este se hace un ajuste de un clasificador por cada *target*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628531d0",
   "metadata": {},
   "source": [
    "##### Regression Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6a983",
   "metadata": {},
   "source": [
    "La clase `LogisticRegression()` en scikit-learn es una implementaci√≥n del algoritmo de regresi√≥n log√≠stica, tambi√©n conocido como logit o MaxEnt, que se utiliza principalmente para problemas de clasificaci√≥n binaria y multiclase. Este algoritmo modela la relaci√≥n entre una variable dependiente categ√≥rica y una o m√°s variables independientes mediante el uso de la funci√≥n log√≠stica para predecir la probabilidad de que una observaci√≥n pertenezca a una determinada categor√≠a.\n",
    "\n",
    "La clase ofrece una variedad de opciones para personalizar el modelo, como la especificaci√≥n del tipo de penalizaci√≥n, el ajuste de la regularizaci√≥n, la elecci√≥n del solver para la optimizaci√≥n, entre otros.\n",
    "\n",
    "M√°s informaci√≥n: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "091125fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.23      0.35        13\n",
      "           1       1.00      0.25      0.40        16\n",
      "           2       0.64      0.88      0.74         8\n",
      "           3       0.71      0.36      0.48        14\n",
      "           4       0.38      0.38      0.38         8\n",
      "           5       0.67      0.27      0.38        15\n",
      "           6       0.43      0.23      0.30        13\n",
      "           7       0.75      0.50      0.60        12\n",
      "           8       0.00      0.00      0.00         8\n",
      "           9       0.91      0.59      0.71        17\n",
      "\n",
      "   micro avg       0.67      0.36      0.47       124\n",
      "   macro avg       0.62      0.37      0.43       124\n",
      "weighted avg       0.68      0.36      0.45       124\n",
      " samples avg       0.51      0.33      0.39       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = LogisticRegression(penalty = 'l2', solver = 'newton-cg', max_iter = 1000,\n",
    "                                     multi_class = 'multinomial', random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "417a9432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.31      0.40        13\n",
      "           1       0.80      0.50      0.62        16\n",
      "           2       0.64      0.88      0.74         8\n",
      "           3       0.70      0.50      0.58        14\n",
      "           4       0.29      0.25      0.27         8\n",
      "           5       0.75      0.40      0.52        15\n",
      "           6       0.56      0.38      0.45        13\n",
      "           7       0.78      0.58      0.67        12\n",
      "           8       0.50      0.12      0.20         8\n",
      "           9       0.89      0.47      0.62        17\n",
      "\n",
      "   micro avg       0.67      0.44      0.53       124\n",
      "   macro avg       0.65      0.44      0.51       124\n",
      "weighted avg       0.68      0.44      0.52       124\n",
      " samples avg       0.58      0.46      0.48       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = PassiveAggressiveClassifier(random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "102daac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.31      0.36        13\n",
      "           1       0.80      0.25      0.38        16\n",
      "           2       0.47      0.88      0.61         8\n",
      "           3       0.56      0.36      0.43        14\n",
      "           4       0.14      0.12      0.13         8\n",
      "           5       0.86      0.40      0.55        15\n",
      "           6       0.42      0.38      0.40        13\n",
      "           7       0.60      0.75      0.67        12\n",
      "           8       0.40      0.25      0.31         8\n",
      "           9       0.75      0.53      0.62        17\n",
      "\n",
      "   micro avg       0.54      0.42      0.47       124\n",
      "   macro avg       0.54      0.42      0.45       124\n",
      "weighted avg       0.59      0.42      0.46       124\n",
      " samples avg       0.51      0.44      0.44       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = SGDClassifier(loss = 'squared_hinge', penalty = 'elasticnet', random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b696cc",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc2e11b",
   "metadata": {},
   "source": [
    "Introducimos ahora para nuestro modelo de `RandomForestClassifier` un acople con `MultiOutputClassifier` para tener un enfoque de uno en uno para cada *target*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9781407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.31      0.42        13\n",
      "           1       0.86      0.75      0.80        16\n",
      "           2       0.50      0.38      0.43         8\n",
      "           3       0.62      0.36      0.45        14\n",
      "           4       0.50      0.25      0.33         8\n",
      "           5       1.00      0.33      0.50        15\n",
      "           6       0.42      0.38      0.40        13\n",
      "           7       0.64      0.75      0.69        12\n",
      "           8       1.00      0.12      0.22         8\n",
      "           9       0.71      0.29      0.42        17\n",
      "\n",
      "   micro avg       0.66      0.41      0.51       124\n",
      "   macro avg       0.69      0.39      0.47       124\n",
      "weighted avg       0.70      0.41      0.49       124\n",
      " samples avg       0.46      0.34      0.37       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = RandomForestClassifier(n_estimators = 3, random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c74db",
   "metadata": {},
   "source": [
    "Vemos que obtenemos mejores resultados que en el caso anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67683bd",
   "metadata": {},
   "source": [
    "##### K-Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c87a7",
   "metadata": {},
   "source": [
    "`KNeighborsClassifier` es un clasificador de vecinos m√°s cercanos implementado en scikit-learn que se utiliza para problemas de clasificaci√≥n supervisada. Este algoritmo clasifica las instancias de datos bas√°ndose en la similitud con los ejemplos de entrenamiento m√°s cercanos en el espacio de caracter√≠sticas. Espec√≠ficamente, asigna una etiqueta a una nueva instancia seg√∫n la mayor√≠a de votos de sus k vecinos m√°s cercanos, donde k es un par√°metro definido por el usuario. `KNeighborsClassifier` es f√°cil de entender e implementar, y es especialmente √∫til para conjuntos de datos peque√±os o medianos donde la relaci√≥n entre las caracter√≠sticas y las etiquetas es no lineal. Antes de utilizar este clasificador, es importante ajustar adecuadamente el valor de k y comprender c√≥mo afecta al rendimiento del modelo en diferentes conjuntos de datos.\n",
    "\n",
    "M√°s informaci√≥n: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a2579a",
   "metadata": {},
   "source": [
    "Los mejores resultados apreciados se obtienen con `n_neighbors = 3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71199765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.15      0.25        13\n",
      "           1       0.38      0.19      0.25        16\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.75      0.21      0.33        14\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.00      0.00      0.00        15\n",
      "           6       0.44      0.31      0.36        13\n",
      "           7       0.40      0.33      0.36        12\n",
      "           8       0.50      0.38      0.43         8\n",
      "           9       0.50      0.29      0.37        17\n",
      "\n",
      "   micro avg       0.41      0.19      0.26       124\n",
      "   macro avg       0.36      0.19      0.24       124\n",
      "weighted avg       0.39      0.19      0.25       124\n",
      " samples avg       0.32      0.20      0.23       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32f52e",
   "metadata": {},
   "source": [
    "De todas formas, los resultados no son buenos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5c074",
   "metadata": {},
   "source": [
    "##### Gradient Boosting: Grid Search (mejor modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7bd242",
   "metadata": {},
   "source": [
    "`GridSearchCV`, que significa Validaci√≥n Cruzada con B√∫squeda de Cuadr√≠cula, es una t√©cnica de b√∫squeda de hiperpar√°metros exhaustiva que se utiliza para encontrar la combinaci√≥n √≥ptima de hiperpar√°metros para un modelo de aprendizaje autom√°tico. Funciona evaluando sistem√°ticamente todas las combinaciones posibles de valores de hiperpar√°metros especificados en una cuadr√≠cula predefinida. Para cada combinaci√≥n de hiperpar√°metros, `GridSearchCV` utiliza la validaci√≥n cruzada para evaluar el rendimiento del modelo en m√∫ltiples divisiones del conjunto de datos de entrenamiento, lo que ayuda a mitigar el riesgo de sobreajuste. Al finalizar la b√∫squeda, devuelve la combinaci√≥n de hiperpar√°metros que produce el mejor rendimiento seg√∫n una m√©trica especificada, como precisi√≥n, puntuaci√≥n F1 o alguna otra medida de rendimiento.\n",
    "\n",
    "`GridSearchCV` es una herramienta poderosa para optimizar los modelos de aprendizaje autom√°tico, ya que automatiza el proceso de ajuste de hiperpar√°metros y ayuda a encontrar la configuraci√≥n que maximiza el rendimiento del modelo en datos no vistos.\n",
    "\n",
    "M√°s informaci√≥n: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "59e6add7-769c-40b6-931b-1fca0721a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters: {'estimator__max_depth': 7, 'estimator__min_samples_split': 2, 'estimator__n_estimators': 60}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.38      0.45        13\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       0.60      0.75      0.67         8\n",
      "           3       0.89      0.57      0.70        14\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      0.93      0.97        15\n",
      "           6       0.80      0.31      0.44        13\n",
      "           7       1.00      0.92      0.96        12\n",
      "           8       0.88      0.88      0.88         8\n",
      "           9       1.00      1.00      1.00        17\n",
      "\n",
      "   micro avg       0.90      0.77      0.83       124\n",
      "   macro avg       0.87      0.77      0.81       124\n",
      "weighted avg       0.89      0.77      0.81       124\n",
      " samples avg       0.88      0.80      0.81       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = GradientBoostingClassifier(loss = 'exponential', random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [40, 50, 60],\n",
    "    'estimator__max_depth': [3, 5, 7],\n",
    "    'estimator__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, average = 'weighted')\n",
    "\n",
    "grid_search = GridSearchCV(multi_target_classifier, param_grid, cv = 5, scoring = f1_scorer, n_jobs = 4, verbose = 1)\n",
    "grid_search.fit(x_train, y_train_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_estimator = grid_search.best_estimator_\n",
    "best_estimator.fit(x_train, y_train_train)\n",
    "\n",
    "y_pred = best_estimator.predict(x_test)\n",
    "\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9846b1",
   "metadata": {},
   "source": [
    "Intentamos mejorar el modelo a√±adiendo un `AdaBoostClassifier` para mejorar el *fitting* del estimador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130b2b9",
   "metadata": {},
   "source": [
    "`AdaBoostClassifier` es un algoritmo de aprendizaje autom√°tico que se utiliza com√∫nmente para la clasificaci√≥n. Es un tipo de algoritmo de conjunto que combina m√∫ltiples modelos de aprendizaje d√©biles para crear un modelo fuerte. El principio b√°sico detr√°s de AdaBoost es entrenar iterativamente una secuencia de clasificadores d√©biles, donde cada clasificador se enfoca en las instancias que los clasificadores anteriores clasificaron incorrectamente. En cada iteraci√≥n, se da m√°s peso a las instancias clasificadas incorrectamente para que el pr√≥ximo clasificador se centre en corregir esos errores. \n",
    "\n",
    "Al final del proceso, los clasificadores d√©biles se combinan mediante votaci√≥n ponderada para formar un clasificador fuerte. AdaBoost es efectivo en una variedad de problemas de clasificaci√≥n y es especialmente √∫til cuando se utilizan clasificadores simples como base, como √°rboles de decisi√≥n con poca profundidad.\n",
    "\n",
    "M√°s informaci√≥n: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a4bdeabe-13e4-48f6-bc3c-0538b3394303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.46      0.60        13\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      0.75      0.86         8\n",
      "           3       0.80      0.57      0.67        14\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      0.93      0.97        15\n",
      "           6       1.00      0.38      0.56        13\n",
      "           7       1.00      0.92      0.96        12\n",
      "           8       0.88      0.88      0.88         8\n",
      "           9       1.00      1.00      1.00        17\n",
      "\n",
      "   micro avg       0.96      0.79      0.87       124\n",
      "   macro avg       0.95      0.79      0.85       124\n",
      "weighted avg       0.95      0.79      0.85       124\n",
      " samples avg       0.88      0.79      0.82       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator = GradientBoostingClassifier(loss = 'exponential', criterion = 'friedman_mse', n_estimators = 50, max_depth = 5, min_samples_split = 5, random_state = seed)\n",
    "base_classifier = AdaBoostClassifier(estimator = estimator, n_estimators = 100, random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train, y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test)\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29487b3a",
   "metadata": {},
   "source": [
    "Los resultados mejoraron ligeramente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838794ad",
   "metadata": {},
   "source": [
    "##### Light Gradient-Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a16f0b",
   "metadata": {},
   "source": [
    "El Light Gradient Boosting Classifier (LightGBM) es una poderosa implementaci√≥n de algoritmo de aumento de gradiente que se destaca por su eficiencia y rendimiento en conjuntos de datos grandes. Utiliza una estrategia de construcci√≥n de √°rboles en hojas, lo que significa que se construyen los nodos hoja primero y luego se dividen hacia atr√°s. Esto reduce significativamente el consumo de memoria y acelera el tiempo de entrenamiento. LightGBM tambi√©n utiliza una t√©cnica de muestreo por gradiente para seleccionar los mejores nodos hoja, lo que mejora la precisi√≥n del modelo y lo hace altamente escalable. Adem√°s, proporciona una variedad de par√°metros para la personalizaci√≥n del modelo y es ampliamente utilizado en problemas de clasificaci√≥n y regresi√≥n en la pr√°ctica de aprendizaje autom√°tico.\n",
    "\n",
    "M√°s informaci√≥n: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e693b9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.58        13\n",
      "           1       0.92      0.75      0.83        16\n",
      "           2       0.71      0.62      0.67         8\n",
      "           3       0.88      0.50      0.64        14\n",
      "           4       1.00      0.75      0.86         8\n",
      "           5       1.00      0.80      0.89        15\n",
      "           6       0.88      0.54      0.67        13\n",
      "           7       1.00      0.83      0.91        12\n",
      "           8       0.88      0.88      0.88         8\n",
      "           9       1.00      1.00      1.00        17\n",
      "\n",
      "   micro avg       0.90      0.73      0.80       124\n",
      "   macro avg       0.89      0.72      0.79       124\n",
      "weighted avg       0.90      0.73      0.80       124\n",
      " samples avg       0.78      0.73      0.73       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_classifier = lgb.LGBMClassifier(boosting_type = 'dart', n_estimators = 50, objective = 'binary', random_state = seed)\n",
    "multi_target_classifier = MultiOutputClassifier(base_classifier, n_jobs = 4)\n",
    "multi_target_classifier.fit(x_train.astype(np.float32), y_train_train)\n",
    "y_pred = multi_target_classifier.predict(x_test.astype(np.float32))\n",
    "report = classification_report(y_train_test, y_pred, zero_division = 0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356c0fe",
   "metadata": {},
   "source": [
    "Los resultados que obtenemos son algo inferiores que en el modelo de `GradientBoostingClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c7119e-b68d-447f-ae89-ef18c223ebf8",
   "metadata": {},
   "source": [
    "## Guardar predicciones de Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0121e",
   "metadata": {},
   "source": [
    "En esta secci√≥n se implementa el c√≥digo para predicci√≥n en nuestro conjunto de `testing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6167ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_testArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89cd23",
   "metadata": {},
   "source": [
    "### Etiquetado de textos sin etiqueta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe47a92",
   "metadata": {},
   "source": [
    "#### Asignaci√≥n de la etiqueta m√°s probable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53288e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-labeled texts: [ 84  85  91  92 108 138 139 140 155 168 169 189]\n"
     ]
    }
   ],
   "source": [
    "zeroIdx = np.where(np.sum(y_test_pred, axis = 1) == 0)[0] # los que tienen todas las etiquetas a 0\n",
    "if zeroIdx.size > 0:\n",
    "    print('Non-labeled texts:', zeroIdx)\n",
    "    probs = model.predict_proba(x_testArray) # probabilidades de cada clase\n",
    "    for idx in zeroIdx:\n",
    "        oneProb = []\n",
    "        for probArray, classes in zip(probs, model.classes_):\n",
    "            p = probArray[idx][classes == 1][0] \n",
    "            oneProb.append(p)\n",
    "        y_test_pred[idx, np.argmax(oneProb)] = 1 # se asigna la clase con prob m√°s alta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ff4d4",
   "metadata": {},
   "source": [
    "#### Active-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbcaa1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainStack = x_train\n",
    "y_trainStack = y_train_train\n",
    "x_testStack = x_testArray\n",
    "y_predStack = y_test_pred\n",
    "\n",
    "zeroIdx = np.where(np.sum(y_predStack, axis = 1) == 0)[0]\n",
    "nZeros = []\n",
    "while zeroIdx.size > 0: # hasta que ya no haya muestras sin etiquetar\n",
    "\n",
    "    model.fit(x_trainStack, y_trainStack)\n",
    "    y_predStack = model.predict(x_testStack)\n",
    "\n",
    "    zeroIdx = np.where(np.sum(y_predStack, axis = 1) == 0)[0]\n",
    "    nZeros.append(zeroIdx.size)\n",
    "\n",
    "    print(x_trainStack.shape, x_testStack.shape, nZeros)\n",
    "\n",
    "    # Si n√∫mero de muestras sin etiquetar es igual en las √∫ltimas 3 iteraciones, se detiene\n",
    "    if len(nZeros) >= 3 and (nZeros[-1] == nZeros[-2] == nZeros[-3]):\n",
    "        raise Exception('Active Learning could not label any sample in the last 2 iterations. Quitting...')\n",
    "\n",
    "    x_lab = x_testStack[[i for i in range(x_testStack.shape[0]) if i not in zeroIdx]]\n",
    "    x_testStack = x_testStack[zeroIdx]\n",
    "\n",
    "    y_lab = y_predStack[[i for i in range(y_predStack.shape[0]) if i not in zeroIdx]]\n",
    "\n",
    "    x_trainStack = vstack([x_trainStack, x_lab])\n",
    "    y_trainStack = np.vstack([y_trainStack, y_lab])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0775823c",
   "metadata": {},
   "source": [
    "### Escritura en fichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff863c1c-9821-4ad4-a912-1abe400f5c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192 entries, 0 to 191\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   archivo  192 non-null    object\n",
      " 1   d49      192 non-null    int32 \n",
      " 2   i10      192 non-null    int32 \n",
      " 3   n28      192 non-null    int32 \n",
      " 4   r10      192 non-null    int32 \n",
      " 5   r11      192 non-null    int32 \n",
      " 6   r50      192 non-null    int32 \n",
      " 7   r52      192 non-null    int32 \n",
      " 8   r59      192 non-null    int32 \n",
      " 9   r60      192 non-null    int32 \n",
      " 10  r69      192 non-null    int32 \n",
      "dtypes: int32(10), object(1)\n",
      "memory usage: 9.1+ KB\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(y_test_pred, index = df_test.index, columns = clases)\n",
    "results.reset_index(inplace = True)\n",
    "\n",
    "results.to_csv('results/bow-multioutput-gradientboosting.csv', index = False)\n",
    "results.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
